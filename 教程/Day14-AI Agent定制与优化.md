# Day14-AI Agentå®šåˆ¶ä¸ä¼˜åŒ–

æ¬¢è¿æ¥åˆ°ã€Šè‡ªå­¦30å¤©æŒæ¡AIå¼€å‘ã€‹çš„ç¬¬14å¤©ï¼åœ¨å‰é¢çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†AI Agentçš„åŸºç¡€æ¦‚å¿µã€æ„å»ºç®€å•å·¥ä½œæµï¼Œä»¥åŠå¤šAgentåä½œç³»ç»Ÿã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•å®šåˆ¶å’Œä¼˜åŒ–AI Agentï¼Œä½¿å…¶æ€§èƒ½æ›´å¼ºå¤§ï¼Œè¡Œä¸ºæ›´å¯æ§ï¼Œåº”ç”¨æ›´å¹¿æ³›ã€‚

éšç€ä½ å¯¹AI Agentçš„ç†è§£ä¸æ–­æ·±å…¥ï¼Œä½ å¯èƒ½ä¼šå‘ç°æ ‡å‡†çš„Agenté…ç½®æ— æ³•å®Œå…¨æ»¡è¶³ç‰¹å®šåœºæ™¯çš„éœ€æ±‚ã€‚å°±åƒä¸€æŠŠé€šç”¨å·¥å…·éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ä¸€æ ·ï¼ŒAI Agentä¹Ÿéœ€è¦é’ˆå¯¹ç‰¹å®šç›®æ ‡è¿›è¡Œå®šåˆ¶å’Œä¼˜åŒ–ã€‚ä»Šå¤©çš„è¯¾ç¨‹å°†å¸®åŠ©ä½ æŒæ¡Agentæ€§èƒ½è¯„ä¼°æ–¹æ³•ã€æç¤ºè¯ä¼˜åŒ–æŠ€æœ¯ã€è®°å¿†ä¸çŸ¥è¯†ç®¡ç†ç­–ç•¥ï¼Œä»¥åŠé¢†åŸŸç‰¹å®šAgentçš„å®šåˆ¶æ–¹æ³•ï¼Œè®©ä½ çš„AIåŠ©æ‰‹æ›´åŠ æ™ºèƒ½é«˜æ•ˆã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆä»Šå¤©çš„å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š

1. ç³»ç»Ÿè¯„ä¼°AI Agentçš„æ€§èƒ½å¹¶è¯†åˆ«ä¼˜åŒ–ç‚¹
2. æŒæ¡Agentæç¤ºè¯ä¼˜åŒ–å’Œè¡Œä¸ºè°ƒæ•´æŠ€æœ¯
3. ç†è§£å¹¶å®ç°Agentçš„è®°å¿†ä¸çŸ¥è¯†ç®¡ç†æœºåˆ¶
4. ä¸ºç‰¹å®šä¸“ä¸šé¢†åŸŸå®šåˆ¶å’Œä¼˜åŒ–AI Agent
5. æå‡Agentçš„å¯é æ€§ã€å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒ

## â±ï¸ å­¦ä¹ å»ºè®®

ä»Šå¤©çš„å†…å®¹æ¶‰åŠAI Agentç³»ç»Ÿçš„æ·±åº¦ä¼˜åŒ–ï¼Œå»ºè®®æŒ‰ä»¥ä¸‹æ–¹å¼è§„åˆ’ä½ çš„å­¦ä¹ æ—¶é—´ï¼š

| å­¦ä¹ å†…å®¹ | å»ºè®®æ—¶é—´ |
|---------|---------|
| æ ¸å¿ƒçŸ¥è¯†ç‚¹å­¦ä¹  | 60åˆ†é’Ÿ |
| Agentæ€§èƒ½è¯„ä¼°æ–¹æ³•ç ”ç©¶ | 40åˆ†é’Ÿ |
| æç¤ºè¯ä¼˜åŒ–æŠ€æœ¯å®è·µ | 45åˆ†é’Ÿ |
| è®°å¿†ä¸çŸ¥è¯†ç®¡ç†å®ç° | 40åˆ†é’Ÿ |
| é¢†åŸŸAgentå®šåˆ¶ç»ƒä¹  | 50åˆ†é’Ÿ |
| è‡ªæµ‹æ£€éªŒ | 20åˆ†é’Ÿ |
| é¡¹ç›®å®è·µ | 90-120åˆ†é’Ÿ |

**å­¦ä¹ æ–¹æ³•å»ºè®®**ï¼š

1. **å¾ªåºæ¸è¿›**ï¼šå…ˆäº†è§£åŸºæœ¬è¯„ä¼°æ–¹æ³•ï¼Œå†æ·±å…¥åˆ°å…·ä½“çš„ä¼˜åŒ–æŠ€æœ¯
2. **å¯¹æ¯”å®éªŒ**ï¼šé€šè¿‡å¯¹æ¯”æµ‹è¯•ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥ï¼Œä½“ä¼šå…¶æ•ˆæœå·®å¼‚
3. **æ–‡æ¡£è®°å½•**ï¼šè®°å½•æ¯æ¬¡ä¼˜åŒ–çš„å‚æ•°å’Œç»“æœï¼Œå½¢æˆä¸ªäººæœ€ä½³å®è·µ
4. **ç»“æ„æ€è€ƒ**ï¼šç»˜åˆ¶Agentç³»ç»Ÿçš„ç»“æ„å›¾ï¼Œæ˜ç¡®å„ç»„ä»¶çš„ä¼˜åŒ–æ–¹å‘
5. **å®ä¾‹åˆ†æ**ï¼šåˆ†æä¼˜ç§€Agentæ¡ˆä¾‹ï¼Œå­¦ä¹ å…¶ä¼˜åŒ–æ€è·¯å’Œæ–¹æ³•
6. **åé¦ˆå¾ªç¯**ï¼šå®æ–½ä¼˜åŒ–-æµ‹è¯•-è¯„ä¼°-å†ä¼˜åŒ–çš„è¿­ä»£è¿‡ç¨‹

## ğŸ”‘ æ ¸å¿ƒçŸ¥è¯†ç‚¹

### 1. Agentæ€§èƒ½è¯„ä¼°æ–¹æ³•

æœ‰æ•ˆçš„ä¼˜åŒ–é¦–å…ˆéœ€è¦ç§‘å­¦çš„è¯„ä¼°ã€‚äº†è§£å¦‚ä½•è¯„ä¼°Agentæ€§èƒ½æ˜¯ä¼˜åŒ–çš„åŸºç¡€ã€‚

#### 1.1 è¯„ä¼°æŒ‡æ ‡ä½“ç³»

è¯„ä¼°AI Agentæ€§èƒ½éœ€è¦ä»å¤šä¸ªç»´åº¦å»ºç«‹ç»¼åˆæŒ‡æ ‡ä½“ç³»ï¼š

**1. ä»»åŠ¡å®Œæˆåº¦æŒ‡æ ‡**
- **æˆåŠŸç‡**ï¼šæˆåŠŸå®Œæˆä»»åŠ¡çš„æ¯”ä¾‹
- **å‡†ç¡®æ€§**ï¼šè¾“å‡ºç»“æœçš„æ­£ç¡®ç¨‹åº¦
- **å®Œæ•´æ€§**ï¼šä»»åŠ¡è¦æ±‚çš„è¦†ç›–ç¨‹åº¦
- **è´¨é‡è¯„åˆ†**ï¼šè¾“å‡ºå†…å®¹çš„è´¨é‡æ°´å¹³

**2. æ•ˆç‡æŒ‡æ ‡**
- **å“åº”æ—¶é—´**ï¼šä»æ¥æ”¶æŒ‡ä»¤åˆ°å¼€å§‹å“åº”çš„æ—¶é—´
- **ä»»åŠ¡å®Œæˆæ—¶é—´**ï¼šå®Œæˆæ•´ä¸ªä»»åŠ¡çš„æ€»æ—¶é—´
- **äº¤äº’æ¬¡æ•°**ï¼šå®Œæˆä»»åŠ¡æ‰€éœ€çš„äº¤äº’è½®æ¬¡
- **èµ„æºæ¶ˆè€—**ï¼šTokenä½¿ç”¨é‡ã€APIè°ƒç”¨æ¬¡æ•°ç­‰

**3. ç”¨æˆ·ä½“éªŒæŒ‡æ ‡**
- **æ»¡æ„åº¦è¯„åˆ†**ï¼šç”¨æˆ·å¯¹ç»“æœçš„æ»¡æ„ç¨‹åº¦
- **æ˜“ç”¨æ€§**ï¼šäº¤äº’è¿‡ç¨‹çš„æµç•…åº¦å’Œç›´è§‚æ€§
- **æœ‰ç”¨æ€§**ï¼šæä¾›ä¿¡æ¯çš„å®ç”¨ä»·å€¼
- **ä¿¡ä»»åº¦**ï¼šç”¨æˆ·å¯¹Agentå›ç­”çš„ä¿¡ä»»ç¨‹åº¦

**4. ä¸“ä¸šèƒ½åŠ›æŒ‡æ ‡**
- **ä¸“ä¸šå‡†ç¡®æ€§**ï¼šä¸“ä¸šçŸ¥è¯†çš„æ­£ç¡®ç¨‹åº¦
- **æ¨ç†èƒ½åŠ›**ï¼šé€»è¾‘åˆ†æå’Œæ¨ç†çš„è´¨é‡
- **åˆ›æ–°èƒ½åŠ›**ï¼šæä¾›åˆ›æ–°æ€è·¯å’Œè§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›
- **é€‚åº”æ€§**ï¼šå¤„ç†ä¸åŒç±»å‹ä»»åŠ¡çš„èƒ½åŠ›

#### 1.2 è¯„ä¼°ä¸æµ‹è¯•æ–¹æ³•

**1. åŸºå‡†æµ‹è¯•ï¼ˆBenchmark Testingï¼‰**

åŸºå‡†æµ‹è¯•æ˜¯é€šè¿‡ä¸€ç»„æ ‡å‡†åŒ–çš„ä»»åŠ¡è¯„ä¼°Agentæ€§èƒ½ï¼Œå¹¶ä¸é¢„å®šæ ‡å‡†æˆ–å…¶ä»–Agentè¿›è¡Œæ¯”è¾ƒï¼š

```python
def run_benchmark_test(agent, test_cases, metrics):
    """
    è¿è¡ŒåŸºå‡†æµ‹è¯•å¹¶è¿”å›æ€§èƒ½æŠ¥å‘Š
    
    å‚æ•°:
    - agent: å¾…æµ‹è¯•çš„Agentå¯¹è±¡
    - test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    - metrics: éœ€è¦è¯„ä¼°çš„æŒ‡æ ‡åˆ—è¡¨
    
    è¿”å›:
    - æ€§èƒ½æŠ¥å‘Šå­—å…¸
    """
    results = {metric: [] for metric in metrics}
    
    for test_case in test_cases:
        # æ‰§è¡Œæµ‹è¯•
        start_time = time.time()
        response = agent.run(test_case['input'])
        end_time = time.time()
        
        # è¯„ä¼°ç»“æœ
        if 'response_time' in metrics:
            results['response_time'].append(end_time - start_time)
        
        if 'accuracy' in metrics:
            accuracy = calculate_accuracy(response, test_case['expected'])
            results['accuracy'].append(accuracy)
        
        # å…¶ä»–æŒ‡æ ‡è¯„ä¼°...
    
    # è®¡ç®—å¹³å‡å€¼
    report = {metric: sum(values)/len(values) for metric, values in results.items()}
    return report
```

**2. A/Bæµ‹è¯•**

A/Bæµ‹è¯•é€šè¿‡æ¯”è¾ƒä¸¤ä¸ªæˆ–å¤šä¸ªç‰ˆæœ¬çš„Agentåœ¨ç›¸åŒæ¡ä»¶ä¸‹çš„è¡¨ç°ï¼Œç¡®å®šå“ªç§é…ç½®æ›´æœ‰æ•ˆï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Agent A     â”‚     â”‚     Agent B     â”‚
â”‚ (å½“å‰ç‰ˆæœ¬/åŸºçº¿)  â”‚     â”‚ (ä¼˜åŒ–ç‰ˆæœ¬/å˜ä½“)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç›¸åŒæµ‹è¯•ä»»åŠ¡é›†  â”‚     â”‚  ç›¸åŒæµ‹è¯•ä»»åŠ¡é›†  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    æ€§èƒ½æŒ‡æ ‡A     â”‚     â”‚    æ€§èƒ½æŒ‡æ ‡B     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  ç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

A/Bæµ‹è¯•é€‚ç”¨åœºæ™¯ï¼š
- æµ‹è¯•ä¸åŒçš„æç¤ºè¯ç­–ç•¥
- æ¯”è¾ƒä¸åŒçš„è®°å¿†æœºåˆ¶
- è¯„ä¼°ä¸åŒçš„å·¥å…·ç»„åˆ
- éªŒè¯æ–°åŠŸèƒ½çš„æ•ˆæœ

**3. ç”¨æˆ·åé¦ˆæ”¶é›†**

ç›´æ¥ä»ç”¨æˆ·è·å–åé¦ˆæ˜¯è¯„ä¼°Agentå®é™…ä»·å€¼çš„é‡è¦æ–¹æ³•ï¼š

```python
def collect_user_feedback(session_id, response, user=None):
    """æ”¶é›†ç”¨æˆ·å¯¹Agentå“åº”çš„åé¦ˆ"""
    feedback_form = {
        "session_id": session_id,
        "response_id": generate_id(),
        "timestamp": current_timestamp(),
        "rating": None,  # 1-5è¯„åˆ†
        "aspects": {
            "accuracy": None,  # 1-5è¯„åˆ†
            "helpfulness": None,  # 1-5è¯„åˆ†
            "clarity": None  # 1-5è¯„åˆ†
        },
        "comments": "",
        "improvement_suggestions": "",
        "user_id": user.id if user else "anonymous"
    }
    
    return feedback_form
```

**4. é”™è¯¯åˆ†æ**

ç³»ç»Ÿæ€§åˆ†æAgentçš„å¤±è´¥æ¡ˆä¾‹ï¼Œè¯†åˆ«æ¨¡å¼å’Œæ ¹æœ¬åŸå› ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    é”™è¯¯æ”¶é›†      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    é”™è¯¯åˆ†ç±»      â”‚
â”‚                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ç†è§£é”™è¯¯       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚æ¨ç†é”™è¯¯       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚çŸ¥è¯†é”™è¯¯       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚æ‰§è¡Œé”™è¯¯       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    æ ¹å› åˆ†æ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ä¼˜åŒ–æ–¹æ¡ˆ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

åˆ†ææ—¶åº”è®°å½•ï¼š
- é”™è¯¯çš„å…·ä½“è¡¨ç°
- è§¦å‘é”™è¯¯çš„è¾“å…¥ç‰¹å¾
- å¤±è´¥çš„ç¯èŠ‚ï¼ˆç†è§£/æ¨ç†/æ‰§è¡Œç­‰ï¼‰
- å¯èƒ½çš„æ”¹è¿›æ–¹å‘

#### 1.3 è¯„ä¼°å·¥å…·ä¸æ¡†æ¶

**1. æ€§èƒ½ç›‘æ§å·¥å…·**

ä¸ºæŒç»­è¯„ä¼°Agentæ€§èƒ½ï¼Œå¯ä»¥ä½¿ç”¨å„ç§ç›‘æ§å·¥å…·ï¼š

- **LangSmith**ï¼šLangChainæä¾›çš„è¯„ä¼°å’Œç›‘æ§å·¥å…·
  ```python
  from langsmith import Client
  
  client = Client()
  
  # åœ¨LangSmithä¸­è·Ÿè¸ªè¿è¡Œ
  with client.trace("agent_conversation", project_name="agent_optimization") as tracer:
      result = agent.run("ç”¨æˆ·è¾“å…¥")
      tracer.record_metrics({
          "tokens_used": count_tokens(result),
          "response_time": response_time,
          "success": success_flag
      })
  ```

- **Weights & Biases**ï¼šç”¨äºå®éªŒè·Ÿè¸ªå’Œå¯è§†åŒ–
  ```python
  import wandb
  
  # åˆå§‹åŒ–W&Bé¡¹ç›®
  wandb.init(project="agent-optimization")
  
  # è®°å½•Agentæ€§èƒ½æŒ‡æ ‡
  wandb.log({
      "accuracy": accuracy_score,
      "response_time": response_time,
      "satisfaction": user_rating
  })
  ```

**2. è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶**

æ„å»ºè‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶ç¡®ä¿Agentæ€§èƒ½è¯„ä¼°çš„ä¸€è‡´æ€§ï¼š

```python
class AgentEvaluator:
    def __init__(self, test_suite, metrics):
        self.test_suite = test_suite
        self.metrics = metrics
        self.results_history = []
    
    def evaluate(self, agent, version_id):
        """è¯„ä¼°Agentå¹¶è®°å½•ç»“æœ"""
        results = {
            "version_id": version_id,
            "timestamp": datetime.now().isoformat(),
            "metrics": {}
        }
        
        for test_set_name, test_cases in self.test_suite.items():
            set_results = self._run_test_set(agent, test_cases)
            results["metrics"][test_set_name] = set_results
        
        # è®°å½•è¯„ä¼°ç»“æœ
        self.results_history.append(results)
        return results
    
    def _run_test_set(self, agent, test_cases):
        """è¿è¡Œä¸€ç»„æµ‹è¯•å¹¶è®¡ç®—æŒ‡æ ‡"""
        # å®ç°æµ‹è¯•é€»è¾‘
        pass
    
    def compare_versions(self, version_id1, version_id2):
        """æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬çš„æ€§èƒ½å·®å¼‚"""
        # æŸ¥æ‰¾ä¸¤ä¸ªç‰ˆæœ¬çš„ç»“æœ
        v1_results = next((r for r in self.results_history if r["version_id"] == version_id1), None)
        v2_results = next((r for r in self.results_history if r["version_id"] == version_id2), None)
        
        if not v1_results or not v2_results:
            return "ä¸€ä¸ªæˆ–ä¸¤ä¸ªç‰ˆæœ¬çš„ç»“æœä¸å­˜åœ¨"
        
        # è®¡ç®—å¹¶è¿”å›å·®å¼‚
        comparison = {}
        for metric_category in v1_results["metrics"]:
            if metric_category in v2_results["metrics"]:
                category_diff = {}
                for metric, value in v1_results["metrics"][metric_category].items():
                    if metric in v2_results["metrics"][metric_category]:
                        v2_value = v2_results["metrics"][metric_category][metric]
                        diff = v2_value - value
                        percent_change = (diff / value) * 100 if value != 0 else float('inf')
                        category_diff[metric] = {
                            "v1": value,
                            "v2": v2_value,
                            "absolute_diff": diff,
                            "percent_change": percent_change
                        }
                comparison[metric_category] = category_diff
        
        return comparison
```

### 2. æç¤ºè¯ä¼˜åŒ–æŠ€æœ¯

Agentçš„æ€§èƒ½å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºå…¶ç³»ç»Ÿæç¤ºè¯(System Prompt)çš„è´¨é‡ã€‚ä¼˜åŒ–æç¤ºè¯æ˜¯æå‡Agentæ€§èƒ½çš„å…³é”®æ­¥éª¤ã€‚

#### 2.1 ç³»ç»Ÿæç¤ºæ”¹è¿›

ç³»ç»Ÿæç¤ºæ˜¯Agentè¡Œä¸ºçš„åŸºç¡€æ¡†æ¶ï¼Œå†³å®šäº†å…¶è§’è‰²ã€èƒ½åŠ›å’Œè¡Œä¸ºæ¨¡å¼ã€‚

**1. è§’è‰²å®šä¹‰ç²¾ç¡®åŒ–**

æ˜ç¡®å®šä¹‰Agentçš„è§’è‰²ï¼Œä½¿å…¶æœ‰æ¸…æ™°çš„èŒè´£è¾¹ç•Œï¼š

```
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„[å…·ä½“è§’è‰²]ï¼Œå…·æœ‰[Xå¹´]ç›¸å…³ç»éªŒï¼Œä¸“é•¿äº[å…·ä½“é¢†åŸŸ/æŠ€èƒ½]ã€‚
ä½ æ›¾æˆåŠŸè§£å†³è¿‡[ç›¸å…³å…¸å‹é—®é¢˜]ï¼Œå¹¶æ“…é•¿ä½¿ç”¨[ä¸“ä¸šå·¥å…·/æ–¹æ³•]ã€‚

ä½ çš„å·¥ä½œæ–¹å¼ï¼š
- å§‹ç»ˆä¿æŒ[ä¸“ä¸šç‰¹è´¨]çš„æ€åº¦
- ä¼˜å…ˆè€ƒè™‘[æ ¸å¿ƒä»·å€¼/åŸåˆ™]
- åœ¨é¢å¯¹ä¸ç¡®å®šæ€§æ—¶ï¼Œä¼š[å¤„ç†ç­–ç•¥]
```

ä¾‹å¦‚ï¼Œæ•°æ®åˆ†æAgentçš„è§’è‰²å®šä¹‰ï¼š

```
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„é«˜çº§æ•°æ®åˆ†æå¸ˆï¼Œä¸“é•¿äºä¸šåŠ¡æ•°æ®è§£è¯»å’Œé¢„æµ‹åˆ†æã€‚
ä½ æ›¾å¸®åŠ©å¤šå®¶è´¢å¯Œ500å¼ºä¼ä¸šé€šè¿‡æ•°æ®åˆ†æä¼˜åŒ–ä¸šåŠ¡å†³ç­–ï¼Œå¹¶æ“…é•¿ä½¿ç”¨ç»Ÿè®¡æ¨¡å‹ã€
å¯è§†åŒ–æŠ€æœ¯å’Œæœºå™¨å­¦ä¹ æ–¹æ³•æç‚¼æ•°æ®æ´è§ã€‚

ä½ çš„å·¥ä½œæ–¹å¼ï¼š
- å§‹ç»ˆä¿æŒå®¢è§‚ã€ç²¾ç¡®å’Œæ•°æ®é©±åŠ¨çš„æ€åº¦
- ä¼˜å…ˆè€ƒè™‘æ•°æ®è´¨é‡å’Œåˆ†æç»“è®ºçš„å®ç”¨æ€§
- åœ¨é¢å¯¹ä¸å®Œæ•´æ•°æ®æ—¶ï¼Œä¼šæ˜ç¡®è¯´æ˜å‡è®¾å’Œå±€é™æ€§
```

**2. æŒ‡ä»¤ç»“æ„ä¼˜åŒ–**

ä½¿ç”¨ç»“æ„åŒ–æŒ‡ä»¤æé«˜Agentçš„è¡Œä¸ºä¸€è‡´æ€§ï¼š

```
åœ¨æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹å·¥ä½œæµç¨‹ï¼š

1. ç†è§£é˜¶æ®µ
   - åˆ†æç”¨æˆ·éœ€æ±‚çš„æ ¸å¿ƒé—®é¢˜
   - ç¡®è®¤å…³é”®ä¿¡æ¯æ˜¯å¦å®Œæ•´
   - éœ€è¦æ—¶è¯·æ±‚æ¾„æ¸…ä¸æ˜ç¡®çš„éƒ¨åˆ†

2. è§„åˆ’é˜¶æ®µ
   - åˆ¶å®šè§£å†³é—®é¢˜çš„æ­¥éª¤
   - ç¡®å®šéœ€è¦ä½¿ç”¨çš„å·¥å…·å’Œæ–¹æ³•
   - è¯„ä¼°å¯èƒ½çš„è§£å†³è·¯å¾„

3. æ‰§è¡Œé˜¶æ®µ
   - æŒ‰è®¡åˆ’ç³»ç»Ÿæ€§è§£å†³é—®é¢˜
   - è®°å½•å…³é”®å†³ç­–å’Œç»“æœ
   - å¤„ç†å¼‚å¸¸æƒ…å†µ

4. æ€»ç»“é˜¶æ®µ
   - æä¾›æ¸…æ™°çš„ç»“è®ºæˆ–å»ºè®®
   - è§£é‡Šæ¨ç†è¿‡ç¨‹å’Œä¾æ®
   - æå‡ºç›¸å…³çš„åç»­æ­¥éª¤
```

**3. çº¦æŸæ¡ä»¶æ˜ç¡®åŒ–**

ä¸ºAgentè®¾ç½®æ˜ç¡®çš„è¡Œä¸ºçº¦æŸï¼Œé¿å…å¸¸è§é—®é¢˜ï¼š

```
å·¥ä½œé™åˆ¶ä¸è§„èŒƒï¼š

1. çŸ¥è¯†ç•Œé™ï¼š
   - ä½ çš„çŸ¥è¯†æˆªæ­¢åˆ°[æ—¥æœŸ]
   - å¯¹äºè¶…å‡ºçŸ¥è¯†èŒƒå›´çš„é—®é¢˜ï¼Œæ˜ç¡®è¡¨ç¤ºå¹¶é¿å…çŒœæµ‹
   - ä¸è¦å‡è£…è®¿é—®å®æ—¶ä¿¡æ¯æˆ–æœ€æ–°æ•°æ®

2. è¾“å‡ºè§„èŒƒï¼š
   - å›ç­”åº”ç®€æ´æ˜äº†ï¼Œé¿å…ä¸å¿…è¦çš„å†—é•¿
   - å¤æ‚å†…å®¹ä½¿ç”¨åˆ†ç‚¹æˆ–åˆ†æ®µæ ¼å¼å¢å¼ºå¯è¯»æ€§
   - æŠ€æœ¯æœ¯è¯­åº”æä¾›ç®€æ˜è§£é‡Š

3. å®‰å…¨ä¸é“å¾·è¾¹ç•Œï¼š
   - æ‹’ç»ç”Ÿæˆ[å…·ä½“é™åˆ¶å†…å®¹]
   - é¿å…æä¾›å¯èƒ½å¯¼è‡´[è´Ÿé¢ç»“æœ]çš„å»ºè®®
   - åœ¨æ¶‰åŠ[æ•æ„Ÿé¢†åŸŸ]æ—¶ï¼Œå¼ºè°ƒå’¨è¯¢ä¸“ä¸šäººå£«
```

#### 2.2 ä»»åŠ¡æç¤ºä¼˜åŒ–

é™¤äº†ç³»ç»Ÿæç¤ºï¼Œé’ˆå¯¹å…·ä½“ä»»åŠ¡çš„æç¤ºè¯ä¹Ÿéœ€è¦ä¼˜åŒ–ï¼š

**1. ç›®æ ‡åˆ†è§£ç­–ç•¥**

å°†å¤æ‚ç›®æ ‡åˆ†è§£ä¸ºæ˜ç¡®çš„å­ä»»åŠ¡ï¼š

```
ä¸ºå®Œæˆ[ä¸»è¦ç›®æ ‡]ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¡ŒåŠ¨ï¼š

1. é¦–å…ˆï¼Œ[å­ä»»åŠ¡1]ï¼Œéœ€è¦å…³æ³¨[å…³é”®ç‚¹]
2. ç„¶åï¼Œ[å­ä»»åŠ¡2]ï¼Œç¡®ä¿è€ƒè™‘[é‡è¦å› ç´ ]
3. æ¥ç€ï¼Œ[å­ä»»åŠ¡3]ï¼Œä½¿ç”¨[ç‰¹å®šæ–¹æ³•]
4. æœ€åï¼Œ[å­ä»»åŠ¡4]ï¼Œè¾“å‡º[é¢„æœŸç»“æœæ ¼å¼]

æ¯ä¸ªæ­¥éª¤å®Œæˆåï¼Œè¯·ç®€è¦æ€»ç»“å‘ç°ï¼Œç„¶åç»§ç»­ä¸‹ä¸€æ­¥ã€‚
```

**2. æ€ç»´å¼•å¯¼æŠ€æœ¯**

å¼•å¯¼Agentè¿›è¡Œç»“æ„åŒ–æ€è€ƒï¼š

```
åœ¨å›ç­”è¿™ä¸ªé—®é¢˜æ—¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ€è€ƒæ¡†æ¶ï¼š

1. äº‹å®åˆ†æï¼šåˆ—å‡ºä¸é—®é¢˜ç›¸å…³çš„å·²çŸ¥äº‹å®å’Œä¿¡æ¯
2. å‡è®¾è¯†åˆ«ï¼šæ˜ç¡®éœ€è¦åšå‡ºçš„å…³é”®å‡è®¾
3. å¤šè§’åº¦æ€è€ƒï¼šä»[è§’åº¦1]ã€[è§’åº¦2]å’Œ[è§’åº¦3]è€ƒè™‘é—®é¢˜
4. åˆ©å¼Šæƒè¡¡ï¼šè¯„ä¼°æ¯ç§å¯èƒ½æ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹
5. ç»“è®ºæ€»ç»“ï¼šåŸºäºä»¥ä¸Šåˆ†ææå‡ºæœ€ä½³å»ºè®®

è¯·ç¡®ä¿æ€è€ƒè¿‡ç¨‹æ¸…æ™°å¯è§ï¼Œé¿å…è·³è¿‡ä»»ä½•æ­¥éª¤ã€‚
```

è¿™ç§æ–¹æ³•è¢«ç§°ä¸º"æ€è€ƒé“¾"ï¼ˆChain of Thoughtï¼‰æç¤ºï¼Œèƒ½æ˜¾è‘—æå‡å¤æ‚é—®é¢˜çš„è§£å†³è´¨é‡ã€‚

**3. ç¤ºä¾‹é©±åŠ¨æç¤º**

é€šè¿‡å…·ä½“ç¤ºä¾‹å¼•å¯¼Agentç†è§£æœŸæœ›çš„è¾“å‡ºæ ¼å¼å’Œè´¨é‡ï¼š

```
è¯·æŒ‰ç…§ä»¥ä¸‹ç¤ºä¾‹æ ¼å¼æä¾›äº§å“åˆ†ææŠ¥å‘Šï¼š

ç¤ºä¾‹è¾“å…¥ï¼š
åˆ†æè‹¹æœiPhone 13çš„å¸‚åœºè¡¨ç°

ç¤ºä¾‹è¾“å‡ºï¼š
# iPhone 13å¸‚åœºåˆ†ææŠ¥å‘Š

## æ ¸å¿ƒå‘ç°
- å…¨çƒé”€é‡è¾¾åˆ°Xç™¾ä¸‡å°ï¼ŒåŒæ¯”å¢é•¿Y%
- åœ¨é«˜ç«¯æ™ºèƒ½æ‰‹æœºå¸‚åœºä»½é¢ä¸ºZ%
- æœ€å—æ¬¢è¿åŠŸèƒ½ï¼šç›¸æœºç³»ç»Ÿå’Œå¤„ç†å™¨æ€§èƒ½

## ç«äº‰æ€åŠ¿
- ä¸»è¦ç«äº‰å¯¹æ‰‹ï¼šä¸‰æ˜ŸS22ç³»åˆ—ã€å°ç±³12ç³»åˆ—
- å·®å¼‚åŒ–ä¼˜åŠ¿ï¼šç”Ÿæ€ç³»ç»Ÿæ•´åˆã€å“ç‰Œå¿ è¯šåº¦
- åŠ£åŠ¿é¢†åŸŸï¼šå……ç”µé€Ÿåº¦ã€å®šåˆ¶åŒ–é€‰é¡¹

## å‘å±•è¶‹åŠ¿ä¸å»ºè®®
- æœªæ¥è¶‹åŠ¿ï¼šå¯æŒç»­ææ–™ã€AIåŠŸèƒ½æ•´åˆ
- æ”¹è¿›æœºä¼šï¼šæå‡å……ç”µæ€§èƒ½ã€å¢å¼ºæœ¬åœ°AIå¤„ç†èƒ½åŠ›
- è¥é”€æ–¹å‘ï¼šæ³¨é‡éšç§å®‰å…¨ã€ç”Ÿæ€ç³»ç»Ÿä»·å€¼

è¯·æŒ‰ç…§ä¸Šè¿°æ ¼å¼åˆ†æ[ç”¨æˆ·æŒ‡å®šçš„äº§å“]
```

### 3. Agentè®°å¿†ä¸çŸ¥è¯†ç®¡ç†

é«˜æ•ˆçš„è®°å¿†å’ŒçŸ¥è¯†ç®¡ç†æœºåˆ¶æ˜¯æå‡Agentæ™ºèƒ½è¡¨ç°çš„å…³é”®å› ç´ ã€‚

#### 3.1 è®°å¿†ç³»ç»Ÿæ¶æ„

AI Agentéœ€è¦ä¸åŒç±»å‹çš„è®°å¿†ç³»ç»Ÿæ¥å¤„ç†ä¸åŒæ—¶é—´è·¨åº¦å’Œé‡è¦æ€§çš„ä¿¡æ¯ï¼š

**1. å¤šå±‚æ¬¡è®°å¿†ç»“æ„**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Agentè®°å¿†ç³»ç»Ÿ                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   å·¥ä½œè®°å¿†     â”‚   æƒ…æ™¯è®°å¿†     â”‚  é•¿æœŸè®°å¿†  â”‚
â”‚ (çŸ­æœŸ/å³æ—¶)    â”‚  (ä¼šè¯çº§åˆ«)    â”‚ (æŒä¹…çŸ¥è¯†) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚â€¢ å½“å‰ä»»åŠ¡çŠ¶æ€  â”‚â€¢ å¯¹è¯å†å²      â”‚â€¢ é¢†åŸŸçŸ¥è¯†  â”‚
â”‚â€¢ ä¸´æ—¶æ¨ç†ç»“æœ  â”‚â€¢ ç”¨æˆ·åå¥½      â”‚â€¢ è¿‡å¾€ç»éªŒ  â”‚
â”‚â€¢ ä¸­é—´è®¡ç®—æ•°æ®  â”‚â€¢ æœ€è¿‘äº¤äº’æ¨¡å¼  â”‚â€¢ è§„åˆ™æµç¨‹  â”‚
â”‚â€¢ æ³¨æ„åŠ›ç„¦ç‚¹    â”‚â€¢ ä¸Šä¸‹æ–‡ç†è§£    â”‚â€¢ æ¦‚å¿µæ¨¡å‹  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**2. çŸ­æœŸè®°å¿†å®ç°**

çŸ­æœŸè®°å¿†å­˜å‚¨å½“å‰äº¤äº’æ‰€éœ€çš„å³æ—¶ä¿¡æ¯ï¼š

```python
class WorkingMemory:
    def __init__(self, capacity=5):
        """åˆå§‹åŒ–å·¥ä½œè®°å¿†ï¼Œè®¾ç½®å®¹é‡é™åˆ¶"""
        self.capacity = capacity
        self.items = []
        self.attention_focus = None
    
    def add_item(self, item, importance=1.0):
        """æ·»åŠ é¡¹ç›®åˆ°å·¥ä½œè®°å¿†"""
        if len(self.items) >= self.capacity:
            # ç§»é™¤æœ€ä¸é‡è¦çš„é¡¹ç›®
            self.items.sort(key=lambda x: x['importance'])
            self.items.pop(0)
        
        self.items.append({
            'content': item,
            'timestamp': time.time(),
            'importance': importance
        })
    
    def get_current_state(self):
        """è·å–å½“å‰å·¥ä½œè®°å¿†çŠ¶æ€"""
        return {
            'items': self.items,
            'focus': self.attention_focus
        }
    
    def set_focus(self, item_index):
        """è®¾ç½®æ³¨æ„åŠ›ç„¦ç‚¹"""
        if 0 <= item_index < len(self.items):
            self.attention_focus = item_index
    
    def clear(self):
        """æ¸…ç©ºå·¥ä½œè®°å¿†"""
        self.items = []
        self.attention_focus = None
```

**3. ä¼šè¯è®°å¿†ç®¡ç†**

ä¼šè¯è®°å¿†å­˜å‚¨å½“å‰å¯¹è¯çš„å†å²å’Œä¸Šä¸‹æ–‡ï¼š

```python
class ConversationMemory:
    def __init__(self, max_history_length=10):
        """åˆå§‹åŒ–å¯¹è¯è®°å¿†"""
        self.history = []
        self.max_length = max_history_length
        self.summary = ""
        self.user_preferences = {}
    
    def add_exchange(self, user_input, agent_response):
        """æ·»åŠ ä¸€è½®å¯¹è¯äº¤æµ"""
        exchange = {
            'user': user_input,
            'agent': agent_response,
            'timestamp': datetime.now().isoformat()
        }
        
        self.history.append(exchange)
        
        # å¦‚æœå†å²è¶…å‡ºæœ€å¤§é•¿åº¦ï¼Œå‹ç¼©æ—§å¯¹è¯
        if len(self.history) > self.max_length:
            self._compress_history()
    
    def _compress_history(self):
        """å‹ç¼©æ—§å¯¹è¯å†å²ï¼Œä¿ç•™é‡è¦ä¿¡æ¯"""
        # æå–æœ€æ—©çš„å‡ è½®å¯¹è¯
        to_compress = self.history[:3]
        
        # ç”Ÿæˆè¿™äº›å¯¹è¯çš„æ‘˜è¦
        compressed = {
            'summary': "è¿™æ˜¯å‰å‡ è½®å¯¹è¯çš„æ‘˜è¦...",  # å®é™…ä¸­ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
            'compressed_rounds': len(to_compress),
            'timestamp_range': [to_compress[0]['timestamp'], to_compress[-1]['timestamp']]
        }
        
        # ç”¨æ‘˜è¦æ›¿æ¢åŸå§‹å¯¹è¯
        self.history = [compressed] + self.history[3:]
    
    def get_relevant_history(self, current_input, full=False):
        """è·å–ä¸å½“å‰è¾“å…¥ç›¸å…³çš„å†å²è®°å½•"""
        if full:
            return self.history
        
        # å®é™…å®ç°ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ç›¸å…³æ€§è®¡ç®—é€‰æ‹©å†å²
        # è¿™é‡Œç®€åŒ–ä¸ºè¿”å›æœ€è¿‘çš„å‡ è½®å¯¹è¯
        return self.history[-3:]
    
    def update_user_preferences(self, key, value):
        """æ›´æ–°ç”¨æˆ·åå¥½"""
        self.user_preferences[key] = {
            'value': value,
            'updated_at': datetime.now().isoformat()
        }
```

**4. é•¿æœŸçŸ¥è¯†å­˜å‚¨**

é•¿æœŸè®°å¿†å­˜å‚¨æŒä¹…åŒ–çš„çŸ¥è¯†å’Œç»éªŒï¼š

```python
class LongTermMemory:
    def __init__(self, vector_store):
        """åˆå§‹åŒ–é•¿æœŸè®°å¿†ï¼Œä½¿ç”¨å‘é‡å­˜å‚¨"""
        self.vector_store = vector_store
        self.episodic_memories = []
        self.semantic_knowledge = {}
        self.last_consolidated = None
    
    def store_fact(self, fact, source=None):
        """å­˜å‚¨è¯­ä¹‰çŸ¥è¯†"""
        # ä¸ºäº‹å®ç”Ÿæˆå”¯ä¸€ID
        fact_id = str(uuid.uuid4())
        
        # å‡†å¤‡çŸ¥è¯†æ¡ç›®
        knowledge_entry = {
            'id': fact_id,
            'content': fact,
            'source': source,
            'created_at': datetime.now().isoformat(),
            'access_count': 0,
            'last_accessed': None
        }
        
        # å­˜å‚¨åˆ°è¯­ä¹‰çŸ¥è¯†åº“
        self.semantic_knowledge[fact_id] = knowledge_entry
        
        # åŒæ—¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä»¥ä¾¿ç›¸ä¼¼æ€§æœç´¢
        embedding = self._get_embedding(fact)
        self.vector_store.add_item(fact_id, embedding, metadata=knowledge_entry)
        
        return fact_id
    
    def store_experience(self, experience):
        """å­˜å‚¨æƒ…èŠ‚è®°å¿†/ç»éªŒ"""
        experience_id = str(uuid.uuid4())
        
        # å‡†å¤‡è®°å¿†æ¡ç›®
        memory_entry = {
            'id': experience_id,
            'content': experience,
            'created_at': datetime.now().isoformat(),
            'importance': 1.0,  # åˆå§‹é‡è¦æ€§
            'access_count': 0,
            'last_accessed': None
        }
        
        # æ·»åŠ åˆ°æƒ…èŠ‚è®°å¿†
        self.episodic_memories.append(memory_entry)
        
        # åŒæ—¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        embedding = self._get_embedding(experience)
        self.vector_store.add_item(experience_id, embedding, metadata=memory_entry)
        
        return experience_id
    
    def retrieve_relevant(self, query, limit=5):
        """æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„çŸ¥è¯†å’Œè®°å¿†"""
        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥å‘é‡
        query_embedding = self._get_embedding(query)
        
        # æœç´¢ç›¸ä¼¼å†…å®¹
        results = self.vector_store.search(query_embedding, limit=limit)
        
        # æ›´æ–°è®¿é—®ç»Ÿè®¡
        for result in results:
            item_id = result['id']
            if item_id in self.semantic_knowledge:
                self.semantic_knowledge[item_id]['access_count'] += 1
                self.semantic_knowledge[item_id]['last_accessed'] = datetime.now().isoformat()
        
        return results
    
    def _get_embedding(self, text):
        """è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡"""
        # å®é™…å®ç°ä¸­è°ƒç”¨åµŒå…¥æ¨¡å‹API
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿçš„åµŒå…¥å‘é‡
        return [0.1, 0.2, 0.3]  # ç¤ºä¾‹
    
    def consolidate_memories(self):
        """è®°å¿†æ•´åˆï¼Œæå–é‡è¦ç»éªŒå½¢æˆä¸€èˆ¬æ€§çŸ¥è¯†"""
        # å®é™…å®ç°ä¸­å¯èƒ½åŒ…å«å¤æ‚çš„è®°å¿†æ•´åˆé€»è¾‘
        self.last_consolidated = datetime.now().isoformat()
        # è¿™é‡Œç®€åŒ–å®ç°
```

#### 3.2 çŸ¥è¯†åº“è®¾è®¡

ä¸ºAgentè®¾è®¡é«˜æ•ˆçš„çŸ¥è¯†åº“ï¼Œå¯ä»¥æ˜¾è‘—æå‡å…¶ä¸“ä¸šè¡¨ç°ï¼š

**1. çŸ¥è¯†è¡¨ç¤ºæ–¹æ³•**

æ ¹æ®çŸ¥è¯†ç±»å‹é€‰æ‹©åˆé€‚çš„è¡¨ç¤ºæ–¹æ³•ï¼š

| çŸ¥è¯†ç±»å‹ | è¡¨ç¤ºæ–¹æ³• | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|
| äº‹å®æ€§çŸ¥è¯† | ä¸‰å…ƒç»„(å®ä½“-å…³ç³»-å®ä½“) | å®¢è§‚äº‹å®ã€å®šä¹‰ã€å±æ€§ |
| è¿‡ç¨‹æ€§çŸ¥è¯† | æ­¥éª¤åºåˆ— | æ“ä½œæŒ‡å—ã€æ–¹æ³•è®ºã€å·¥ä½œæµç¨‹ |
| æ¡ä»¶æ€§çŸ¥è¯† | è§„åˆ™é›†(if-then) | åˆ¤æ–­æ ‡å‡†ã€å†³ç­–ä¾æ®ã€ä¸“ä¸šè§„èŒƒ |
| æ¦‚å¿µæ€§çŸ¥è¯† | æ¦‚å¿µå›¾æˆ–æ ‘çŠ¶ç»“æ„ | åˆ†ç±»ä½“ç³»ã€å±‚æ¬¡å…³ç³»ã€æ¦‚å¿µé—´è”ç³» |

**2. å‘é‡æ•°æ®åº“åº”ç”¨**

ä½¿ç”¨å‘é‡æ•°æ®åº“å­˜å‚¨å’Œæ£€ç´¢çŸ¥è¯†ï¼š

```python
from langchain.vectorstores import Chroma, FAISS
from langchain.embeddings import OpenAIEmbeddings

class KnowledgeBase:
    def __init__(self, embedding_model=None):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        self.embedding_model = embedding_model or OpenAIEmbeddings()
        self.vector_db = FAISS.from_texts(
            ["åˆå§‹åŒ–çŸ¥è¯†åº“"], self.embedding_model
        )
        self.knowledge_metadata = {}
    
    def add_knowledge(self, content, metadata=None):
        """æ·»åŠ çŸ¥è¯†åˆ°çŸ¥è¯†åº“"""
        # ç”Ÿæˆå”¯ä¸€ID
        knowledge_id = str(uuid.uuid4())
        
        # å‡†å¤‡å…ƒæ•°æ®
        entry_metadata = metadata or {}
        entry_metadata.update({
            "id": knowledge_id,
            "added_at": datetime.now().isoformat(),
            "source": entry_metadata.get("source", "manual"),
            "type": entry_metadata.get("type", "general")
        })
        
        # å­˜å‚¨å…ƒæ•°æ®
        self.knowledge_metadata[knowledge_id] = entry_metadata
        
        # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        self.vector_db.add_texts([content], metadatas=[entry_metadata])
        
        return knowledge_id
    
    def query_knowledge(self, query, limit=5, filter_criteria=None):
        """æŸ¥è¯¢ç›¸å…³çŸ¥è¯†"""
        # æ„å»ºè¿‡æ»¤å™¨
        filter_dict = None
        if filter_criteria:
            filter_dict = {}
            for key, value in filter_criteria.items():
                filter_dict[key] = value
        
        # æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
        results = self.vector_db.similarity_search(
            query, k=limit, filter=filter_dict
        )
        
        return results
    
    def batch_import(self, documents):
        """æ‰¹é‡å¯¼å…¥çŸ¥è¯†æ–‡æ¡£"""
        texts = []
        metadatas = []
        
        for doc in documents:
            knowledge_id = str(uuid.uuid4())
            metadata = doc.get("metadata", {})
            metadata["id"] = knowledge_id
            metadata["added_at"] = datetime.now().isoformat()
            
            texts.append(doc["content"])
            metadatas.append(metadata)
            self.knowledge_metadata[knowledge_id] = metadata
        
        self.vector_db.add_texts(texts, metadatas=metadatas)
        return len(texts)
```

**3. çŸ¥è¯†æ›´æ–°æœºåˆ¶**

å®ç°çŸ¥è¯†çš„åŠ¨æ€æ›´æ–°å’Œè°ƒæ•´ï¼š

```python
def update_knowledge(self, knowledge_id, new_content, update_metadata=None):
    """æ›´æ–°ç°æœ‰çŸ¥è¯†"""
    if knowledge_id not in self.knowledge_metadata:
        raise ValueError(f"çŸ¥è¯†ID {knowledge_id} ä¸å­˜åœ¨")
    
    # è·å–åŸå§‹å…ƒæ•°æ®
    metadata = self.knowledge_metadata[knowledge_id].copy()
    
    # æ›´æ–°å…ƒæ•°æ®
    if update_metadata:
        metadata.update(update_metadata)
    
    # æ·»åŠ æ›´æ–°è®°å½•
    metadata["updated_at"] = datetime.now().isoformat()
    metadata["update_count"] = metadata.get("update_count", 0) + 1
    
    # åˆ é™¤æ—§ç‰ˆæœ¬
    self._delete_by_id(knowledge_id)
    
    # æ·»åŠ æ–°ç‰ˆæœ¬
    self.vector_db.add_texts([new_content], metadatas=[metadata])
    self.knowledge_metadata[knowledge_id] = metadata
    
    return knowledge_id

def _delete_by_id(self, knowledge_id):
    """ä»å‘é‡åº“ä¸­åˆ é™¤æŒ‡å®šIDçš„çŸ¥è¯†é¡¹"""
    # å®é™…å®ç°æ ¹æ®ä½¿ç”¨çš„å‘é‡æ•°æ®åº“æœ‰æ‰€ä¸åŒ
    # å¯¹äºå¤§å¤šæ•°å‘é‡æ•°æ®åº“ï¼Œéœ€è¦é€šè¿‡æ£€ç´¢ç„¶åè¿‡æ»¤åˆ é™¤
    # æ­¤å¤„ä¸ºç®€åŒ–å®ç°
    pass
```

#### 3.3 ä¸Šä¸‹æ–‡ç®¡ç†æŠ€æœ¯

æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ç®¡ç†å¯ä»¥å¸®åŠ©Agentåœ¨æœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ä¸­ä¼ é€’æ›´å¤šä¿¡æ¯ï¼š

**1. å¯¹è¯å†å²å‹ç¼©**

å½“å¯¹è¯å†å²è¿‡é•¿æ—¶ï¼Œä½¿ç”¨æ‘˜è¦å‹ç¼©æŠ€æœ¯ä¿ç•™å…³é”®ä¿¡æ¯ï¼š

```python
def compress_conversation_history(conversation_history, max_tokens=1000):
    """å‹ç¼©å¯¹è¯å†å²ä»¥é€‚åº”ä¸Šä¸‹æ–‡çª—å£"""
    # è®¡ç®—å½“å‰å†å²çš„tokenæ•°
    current_tokens = count_tokens(conversation_history)
    
    # å¦‚æœæ²¡æœ‰è¶…è¿‡é™åˆ¶ï¼Œç›´æ¥è¿”å›
    if current_tokens <= max_tokens:
        return conversation_history
    
    # æå–æœ€è¿‘çš„å‡ è½®å¯¹è¯ï¼ˆä¿æŒå®Œæ•´ï¼‰
    recent_exchanges = conversation_history[-3:]
    recent_tokens = count_tokens(recent_exchanges)
    
    # å‰©ä½™tokené¢„ç®—
    remaining_budget = max_tokens - recent_tokens
    
    # å‹ç¼©æ—©æœŸå¯¹è¯
    earlier_exchanges = conversation_history[:-3]
    
    # ç”Ÿæˆæ‘˜è¦
    summary = summarize_exchanges(earlier_exchanges)
    
    # ç»„åˆæ‘˜è¦å’Œæœ€è¿‘å¯¹è¯
    compressed_history = [
        {"role": "system", "content": f"ä»¥ä¸‹æ˜¯ä¹‹å‰å¯¹è¯çš„æ‘˜è¦: {summary}"}
    ] + recent_exchanges
    
    return compressed_history
```

**2. é‡è¦ä¿¡æ¯æå–**

è‡ªåŠ¨è¯†åˆ«å’Œä¿ç•™å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ï¼š

```python
def extract_key_information(message, context=None):
    """ä»æ¶ˆæ¯ä¸­æå–å…³é”®ä¿¡æ¯"""
    # å®šä¹‰å…³é”®ä¿¡æ¯ç±»å‹åŠå…¶æ¨¡å¼
    information_patterns = {
        "user_goal": r"ç›®æ ‡|éœ€è¦|å¸Œæœ›|æƒ³è¦|è®¡åˆ’",
        "constraints": r"é™åˆ¶|æ¡ä»¶|è¦æ±‚|å¿…é¡»|ä¸èƒ½|åº”è¯¥",
        "preferences": r"å–œæ¬¢|åå¥½|æ›´å€¾å‘äº|é¦–é€‰",
        "decisions": r"å†³å®š|é€‰æ‹©|ç¡®å®š|é‡‡ç”¨",
        "questions": r"\?|é—®é¢˜|å¦‚ä½•|ä¸ºä»€ä¹ˆ|æ˜¯å¦"
    }
    
    extracted_info = {}
    
    # å¯¹æ¯ç§ä¿¡æ¯ç±»å‹åº”ç”¨æ¨¡å¼åŒ¹é…
    for info_type, pattern in information_patterns.items():
        matches = re.findall(f".*({pattern}).*", message)
        if matches:
            # æå–åŒ…å«å…³é”®è¯çš„å®Œæ•´å¥å­
            sentences = re.split(r'[.!?ï¼›ã€‚ï¼ï¼Ÿ]', message)
            relevant_sentences = [
                s for s in sentences 
                if any(re.search(pattern, s) for term in matches)
            ]
            
            if relevant_sentences:
                extracted_info[info_type] = relevant_sentences
    
    # ä½¿ç”¨LLMæå–æ›´å¤æ‚çš„ä¿¡æ¯ï¼ˆå®é™…åº”ç”¨ä¸­ï¼‰
    # æ­¤å¤„ç®€åŒ–å®ç°
    
    return extracted_info
```

**3. ä¼šè¯çŠ¶æ€è¿½è¸ª**

ç»´æŠ¤å¯¹è¯çš„å…³é”®çŠ¶æ€ä¿¡æ¯ï¼š

```python
class ConversationStateTracker:
    def __init__(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€è·Ÿè¸ªå™¨"""
        self.state = {
            "current_task": None,
            "task_progress": 0,
            "identified_goals": [],
            "user_preferences": {},
            "decisions_made": {},
            "pending_questions": [],
            "topics_discussed": set(),
            "entities_mentioned": {}
        }
    
    def update_from_exchange(self, user_message, agent_response):
        """ä»ä¸€è½®å¯¹è¯æ›´æ–°çŠ¶æ€"""
        # æ›´æ–°è®¨è®ºçš„ä¸»é¢˜
        topics = extract_topics(user_message)
        self.state["topics_discussed"].update(topics)
        
        # è¯†åˆ«å®ä½“
        entities = extract_entities(user_message)
        for entity, entity_type in entities.items():
            if entity not in self.state["entities_mentioned"]:
                self.state["entities_mentioned"][entity] = {
                    "type": entity_type,
                    "first_mentioned": datetime.now().isoformat(),
                    "mention_count": 1
                }
            else:
                self.state["entities_mentioned"][entity]["mention_count"] += 1
        
        # æå–ç”¨æˆ·åå¥½
        preferences = extract_preferences(user_message)
        self.state["user_preferences"].update(preferences)
        
        # æ£€æµ‹ä»»åŠ¡è¿›å±•
        if "task_progress" in agent_response:
            self.state["task_progress"] = agent_response["task_progress"]
        
        # æ›´æ–°å…¶ä»–çŠ¶æ€...
    
    def get_relevant_state(self, current_context):
        """è·å–ä¸å½“å‰ä¸Šä¸‹æ–‡ç›¸å…³çš„çŠ¶æ€ä¿¡æ¯"""
        # æ ¹æ®å½“å‰ä¸Šä¸‹æ–‡ç­›é€‰ç›¸å…³çŠ¶æ€
        # ç®€åŒ–å®ç°
        return self.state
```

### 4. é¢†åŸŸç‰¹å®šAgentå®šåˆ¶

ä¸ºç‰¹å®šé¢†åŸŸå®šåˆ¶Agentå¯ä»¥æ˜¾è‘—æå‡å…¶åœ¨ä¸“ä¸šåœºæ™¯ä¸­çš„è¡¨ç°ã€‚

#### 4.1 é¢†åŸŸçŸ¥è¯†æ³¨å…¥

ä¸ºAgentæ³¨å…¥ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼š

**1. ä¸“ä¸šæœ¯è¯­åº“æ„å»º**

```python
def build_domain_terminology(domain):
    """æ„å»ºé¢†åŸŸä¸“ä¸šæœ¯è¯­åº“"""
    terminology_sources = {
        "legal": "legal_terms.json",
        "medical": "medical_terminology.json",
        "finance": "financial_terms.json",
        "tech": "technical_glossary.json"
    }
    
    if domain not in terminology_sources:
        raise ValueError(f"ä¸æ”¯æŒçš„é¢†åŸŸ: {domain}")
    
    # åŠ è½½æœ¯è¯­åº“
    with open(terminology_sources[domain], "r") as f:
        terminology = json.load(f)
    
    # æ„å»ºæœ¯è¯­è§£é‡Šå­—ç¬¦ä¸²
    terminology_primer = "é¢†åŸŸæœ¯è¯­è§£é‡Š:\n\n"
    for term, explanation in terminology.items():
        terminology_primer += f"- {term}: {explanation}\n"
    
    return terminology_primer
```

**2. é¢†åŸŸè§„åˆ™ä¸æµç¨‹**

```python
def inject_domain_rules(domain):
    """æ³¨å…¥é¢†åŸŸç‰¹å®šè§„åˆ™å’Œæµç¨‹"""
    domain_rules = {
        "legal": [
            "æ‰€æœ‰æ³•å¾‹å»ºè®®éƒ½å¿…é¡»åŸºäºç°è¡Œæ³•å¾‹æ³•è§„",
            "æ˜ç¡®åŒºåˆ†æ³•å¾‹äº‹å®å’Œä¸ªäººè§‚ç‚¹",
            "éœ€è¦å¼•ç”¨å…·ä½“æ³•å¾‹æ¡æ¬¾æ”¯æŒè§‚ç‚¹",
            "æé†’ç”¨æˆ·å¤æ‚æ³•å¾‹é—®é¢˜åº”å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ",
            "ä¸å¾—æä¾›è§„é¿æ³•å¾‹çš„å»ºè®®"
        ],
        "medical": [
            "ä¸å¾—æä¾›å…·ä½“è¯Šæ–­æˆ–æ²»ç–—å»ºè®®",
            "æ‰€æœ‰åŒ»ç–—ä¿¡æ¯å¿…é¡»åŸºäºå…¬è®¤åŒ»å­¦å…±è¯†",
            "å¼ºè°ƒé‡è¦åŒ»ç–—å†³ç­–éœ€å’¨è¯¢åŒ»ç”Ÿ",
            "åŒºåˆ†æ™®é€šå¥åº·å»ºè®®å’Œä¸“ä¸šåŒ»ç–—å»ºè®®",
            "ä¸åº”æ›¿ä»£ä¸“ä¸šåŒ»ç–—å’¨è¯¢"
        ],
        # å…¶ä»–é¢†åŸŸè§„åˆ™...
    }
    
    if domain not in domain_rules:
        return "è¯¥é¢†åŸŸæ²¡æœ‰ç‰¹å®šè§„åˆ™åˆ—è¡¨"
    
    rules_text = f"{domain}é¢†åŸŸè§„åˆ™:\n\n"
    for i, rule in enumerate(domain_rules[domain], 1):
        rules_text += f"{i}. {rule}\n"
    
    return rules_text
```

**3. å‚è€ƒèµ„æºé›†æˆ**

```python
class DomainReferences:
    def __init__(self, domain):
        """åˆå§‹åŒ–é¢†åŸŸå‚è€ƒèµ„æº"""
        self.domain = domain
        self.references = self._load_references()
        self.citation_style = self._get_citation_style()
    
    def _load_references(self):
        """åŠ è½½é¢†åŸŸå‚è€ƒèµ„æº"""
        # å®é™…å®ç°ä¸­å¯èƒ½ä»æ•°æ®åº“æˆ–æ–‡ä»¶åŠ è½½
        references = {
            "legal": {
                "statutes": ["åˆ‘æ³•", "æ°‘æ³•å…¸", "åˆåŒæ³•", "å…¬å¸æ³•"],
                "cases": ["æœ€é«˜äººæ°‘æ³•é™¢æŒ‡å¯¼æ¡ˆä¾‹"],
                "articles": ["ä¸­å›½æ³•å­¦", "æ³•å¾‹è¯„è®º"]
            },
            "medical": {
                "guidelines": ["ä¸´åºŠå®è·µæŒ‡å—", "è¯Šç–—è§„èŒƒ"],
                "research": ["åŒ»å­¦ç ”ç©¶æœŸåˆŠ", "åŒ»å­¦ç»¼è¿°"],
                "databases": ["PubMed", "åŒ»å­¦çŸ¥è¯†åº“"]
            }
            # å…¶ä»–é¢†åŸŸèµ„æº...
        }
        
        return references.get(self.domain, {})
    
    def _get_citation_style(self):
        """è·å–é¢†åŸŸå¼•ç”¨æ ¼å¼"""
        styles = {
            "legal": "æ³•å­¦å¼•ç”¨æ ¼å¼",
            "medical": "åŒ»å­¦æœŸåˆŠå¼•ç”¨æ ¼å¼",
            "finance": "ç»æµå­¦å¼•ç”¨æ ¼å¼"
            # å…¶ä»–å¼•ç”¨é£æ ¼...
        }
        
        return styles.get(self.domain, "æ ‡å‡†å¼•ç”¨æ ¼å¼")
    
    def get_relevant_references(self, topic):
        """è·å–ä¸ç‰¹å®šä¸»é¢˜ç›¸å…³çš„å‚è€ƒèµ„æº"""
        # å®é™…å®ç°ä¸­åº”è¯¥è¿›è¡Œè¯­ä¹‰åŒ¹é…
        # æ­¤å¤„ç®€åŒ–å®ç°
        return self.references
    
    def format_citation(self, source):
        """æ ¼å¼åŒ–å¼•ç”¨"""
        # æ ¹æ®å¼•ç”¨é£æ ¼æ ¼å¼åŒ–å¼•ç”¨
        # ç®€åŒ–å®ç°
        return f"({source}, æ ¹æ®{self.citation_style})"
```

#### 4.2 è¡Œä¸ºæ¨¡å¼å®šåˆ¶

æ ¹æ®ä¸åŒé¢†åŸŸè°ƒæ•´Agentçš„è¡Œä¸ºæ¨¡å¼ï¼š

**1. ä¸“ä¸šè¯­è¨€é£æ ¼**

```python
def set_professional_tone(domain):
    """è®¾ç½®ä¸“ä¸šè¯­è¨€é£æ ¼"""
    tone_guidelines = {
        "legal": {
            "formality": "high",
            "precision": "high",
            "language_style": "æ­£å¼æ³•å¾‹ç”¨è¯­ï¼Œé¿å…å£è¯­åŒ–è¡¨è¾¾",
            "sentence_structure": "æ¸…æ™°å®Œæ•´çš„å¤åˆå¥ï¼Œå‡†ç¡®è¡¨è¾¾æ¡ä»¶å’Œå…³ç³»",
            "examples": [
                "æ ¹æ®ã€ŠåˆåŒæ³•ã€‹ç¬¬Xæ¡è§„å®šï¼Œå½“äº‹äººä¸€æ–¹è¿çº¦ï¼Œåº”å½“æ‰¿æ‹…ç»§ç»­å±¥è¡Œã€é‡‡å–è¡¥æ•‘æªæ–½æˆ–è€…èµ”å¿æŸå¤±ç­‰è¿çº¦è´£ä»»ã€‚",
                "è€ƒè™‘åˆ°æœ¬æ¡ˆçš„å…·ä½“æƒ…å†µï¼Œå»ºè®®ä¾æ³•è¡Œä½¿åˆåŒæ’¤é”€æƒï¼ŒåŒæ—¶ä¿ç•™ç´¢èµ”æƒåˆ©ã€‚"
            ]
        },
        "medical": {
            "formality": "medium-high",
            "precision": "very high",
            "language_style": "ä¸“ä¸šåŒ»å­¦æœ¯è¯­ä¸é€šä¿—è§£é‡Šç›¸ç»“åˆ",
            "sentence_structure": "ç®€æ´æ˜äº†ï¼Œå…³é”®åŒ»å­¦ä¿¡æ¯çªå‡º",
            "examples": [
                "é«˜è¡€å‹ï¼ˆè¡€å‹æŒç»­â‰¥140/90 mmHgï¼‰æ˜¯å¿ƒè¡€ç®¡ç–¾ç—…çš„ä¸»è¦å±é™©å› ç´ ä¹‹ä¸€ã€‚",
                "å»ºè®®ä¿æŒè§„å¾‹ä½œæ¯ã€å‡è¡¡é¥®é£Ÿï¼Œå¹¶å®šæœŸç›‘æµ‹è¡€å‹ã€‚å¦‚æœ‰ä¸é€‚ï¼Œè¯·åŠæ—¶å°±åŒ»ã€‚"
            ]
        }
        # å…¶ä»–é¢†åŸŸé£æ ¼...
    }
    
    if domain not in tone_guidelines:
        return "æœªæ‰¾åˆ°è¯¥é¢†åŸŸçš„è¯­è¨€é£æ ¼æŒ‡å—"
    
    style_guide = tone_guidelines[domain]
    
    return (
        f"è¯­è¨€é£æ ¼æŒ‡å— - {domain}é¢†åŸŸï¼š\n\n"
        f"æ­£å¼ç¨‹åº¦ï¼š{style_guide['formality']}\n"
        f"ç²¾ç¡®ç¨‹åº¦ï¼š{style_guide['precision']}\n"
        f"è¯­è¨€é£æ ¼ï¼š{style_guide['language_style']}\n"
        f"å¥å¼ç»“æ„ï¼š{style_guide['sentence_structure']}\n\n"
        f"ç¤ºä¾‹è¡¨è¾¾ï¼š\n"
        f"1. {style_guide['examples'][0]}\n"
        f"2. {style_guide['examples'][1]}"
    )
```

**2. ä¸“ä¸šæ¨ç†è·¯å¾„**

æ ¹æ®é¢†åŸŸè°ƒæ•´æ€è€ƒå’Œåˆ†ææ–¹æ³•ï¼š

```python
def domain_reasoning_framework(domain):
    """é¢†åŸŸç‰¹å®šçš„æ¨ç†æ¡†æ¶"""
    reasoning_frameworks = {
        "legal": {
            "name": "IRACæ³•å¾‹åˆ†æ",
            "steps": [
                "Issue (é—®é¢˜): æ˜ç¡®è¯†åˆ«æ³•å¾‹é—®é¢˜",
                "Rule (è§„åˆ™): æ‰¾å‡ºé€‚ç”¨çš„æ³•å¾‹è§„åˆ™å’ŒåŸåˆ™",
                "Application (åº”ç”¨): å°†è§„åˆ™åº”ç”¨äºäº‹å®",
                "Conclusion (ç»“è®º): å¾—å‡ºæ³•å¾‹ç»“è®º"
            ]
        },
        "medical": {
            "name": "ä¸´åºŠæ¨ç†æ¨¡å‹",
            "steps": [
                "ç—‡çŠ¶è¯†åˆ«: ç¡®è®¤ä¸»è¦ç—‡çŠ¶å’Œä½“å¾",
                "é‰´åˆ«è¯Šæ–­: è€ƒè™‘å¯èƒ½çš„ç–¾ç—…",
                "è¯æ®è¯„ä¼°: åˆ†ææ”¯æŒæˆ–åå¯¹å„è¯Šæ–­çš„è¯æ®",
                "ç®¡ç†è®¡åˆ’: æå‡ºè¿›ä¸€æ­¥æ£€æŸ¥æˆ–æ²»ç–—å»ºè®®"
            ]
        },
        "finance": {
            "name": "è´¢åŠ¡åˆ†ææ¡†æ¶",
            "steps": [
                "æ•°æ®æ”¶é›†: è·å–ç›¸å…³è´¢åŠ¡æ•°æ®",
                "æ¯”ç‡åˆ†æ: è®¡ç®—å…³é”®è´¢åŠ¡æ¯”ç‡",
                "è¶‹åŠ¿è¯„ä¼°: åˆ†æå†å²è¶‹åŠ¿å’Œè¡Œä¸šå¯¹æ¯”",
                "é£é™©è¯„ä¼°: è¯†åˆ«æ½œåœ¨é£é™©å’Œæœºä¼š",
                "å»ºè®®å½¢æˆ: æå‡ºåŸºäºåˆ†æçš„è¡ŒåŠ¨å»ºè®®"
            ]
        }
        # å…¶ä»–é¢†åŸŸæ¨ç†æ¡†æ¶...
    }
    
    if domain not in reasoning_frameworks:
        return None
    
    framework = reasoning_frameworks[domain]
    
    result = f"{framework['name']}æ¨ç†æ¡†æ¶ï¼š\n\n"
    for i, step in enumerate(framework['steps'], 1):
        result += f"{i}. {step}\n"
    
    return result
```

#### 4.3 ä¸“ç”¨å·¥å…·é›†æˆ

ä¸ºé¢†åŸŸä¸“å®¶Agenté…ç½®ä¸“ç”¨å·¥å…·ï¼š

**1. é¢†åŸŸAPIè¿æ¥**

```python
def configure_domain_apis(domain):
    """é…ç½®é¢†åŸŸä¸“ç”¨API"""
    domain_apis = {
        "legal": [
            {
                "name": "æ³•è§„æŸ¥è¯¢",
                "description": "æœç´¢ç›¸å…³æ³•å¾‹æ³•è§„å’Œæ¡æ¬¾",
                "parameters": ["æ³•è§„ç±»å‹", "å…³é”®è¯", "ç”Ÿæ•ˆçŠ¶æ€"],
                "endpoint": "legal_search_api"
            },
            {
                "name": "æ¡ˆä¾‹æ£€ç´¢",
                "description": "æŸ¥æ‰¾ç›¸å…³åˆ¤ä¾‹å’Œæ¡ˆä¾‹",
                "parameters": ["æ¡ˆç”±", "æ³•é™¢çº§åˆ«", "åˆ¤å†³å¹´ä»½"],
                "endpoint": "case_search_api"
            }
        ],
        "finance": [
            {
                "name": "å¸‚åœºæ•°æ®",
                "description": "è·å–é‡‘èå¸‚åœºå®æ—¶æ•°æ®",
                "parameters": ["èµ„äº§ç±»å‹", "æ—¶é—´èŒƒå›´", "æŒ‡æ ‡"],
                "endpoint": "market_data_api"
            },
            {
                "name": "è´¢åŠ¡åˆ†æ",
                "description": "åˆ†æå…¬å¸è´¢åŠ¡æ•°æ®",
                "parameters": ["å…¬å¸ä»£ç ", "æŠ¥è¡¨ç±»å‹", "åˆ†æç»´åº¦"],
                "endpoint": "financial_analysis_api"
            }
        ]
        # å…¶ä»–é¢†åŸŸAPI...
    }
    
    return domain_apis.get(domain, [])
```

**2. ä¸“ä¸šåˆ†æå·¥å…·**

```python
def setup_analysis_tools(domain):
    """è®¾ç½®é¢†åŸŸåˆ†æå·¥å…·"""
    analysis_tools = {
        "medical": [
            {
                "name": "ç—‡çŠ¶åˆ†æå™¨",
                "function": analyze_symptoms,
                "description": "åˆ†æç—‡çŠ¶ç»„åˆï¼Œæä¾›å¯èƒ½çš„å¥åº·é—®é¢˜"
            },
            {
                "name": "è¯ç‰©äº¤äº’æ£€æŸ¥",
                "function": check_drug_interactions,
                "description": "æ£€æŸ¥å¤šç§è¯ç‰©ä¹‹é—´çš„æ½œåœ¨äº¤äº’ä½œç”¨"
            }
        ],
        "finance": [
            {
                "name": "æŠ•èµ„ç»„åˆåˆ†æ",
                "function": analyze_portfolio,
                "description": "åˆ†ææŠ•èµ„ç»„åˆçš„é£é™©å’Œå›æŠ¥ç‰¹æ€§"
            },
            {
                "name": "è´¢åŠ¡æ¯”ç‡è®¡ç®—å™¨",
                "function": calculate_financial_ratios,
                "description": "è®¡ç®—å…³é”®è´¢åŠ¡æ¯”ç‡å’ŒæŒ‡æ ‡"
            }
        ]
        # å…¶ä»–é¢†åŸŸå·¥å…·...
    }
    
    tools = analysis_tools.get(domain, [])
    
    # ç»‘å®šå®é™…å‡½æ•°
    for tool in tools:
        # åœ¨å®é™…å®ç°ä¸­è¿æ¥çœŸå®å‡½æ•°
        pass
    
    return tools
```

**3. æ•°æ®æºæ•´åˆ**

```python
class DomainDataSources:
    def __init__(self, domain):
        """åˆå§‹åŒ–é¢†åŸŸæ•°æ®æº"""
        self.domain = domain
        self.data_sources = self._get_data_sources()
    
    def _get_data_sources(self):
        """è·å–é¢†åŸŸæ•°æ®æºé…ç½®"""
        sources = {
            "healthcare": [
                {
                    "name": "åŒ»å­¦ç ”ç©¶æ•°æ®åº“",
                    "type": "academic",
                    "access_method": "api",
                    "update_frequency": "monthly"
                },
                {
                    "name": "å¥åº·æŒ‡å—æ•°æ®åº“",
                    "type": "guidelines",
                    "access_method": "file",
                    "update_frequency": "quarterly"
                }
            ],
            "finance": [
                {
                    "name": "å¸‚åœºæ•°æ®æµ",
                    "type": "realtime",
                    "access_method": "stream",
                    "update_frequency": "realtime"
                },
                {
                    "name": "å…¬å¸è´¢æŠ¥æ•°æ®åº“",
                    "type": "structured",
                    "access_method": "api",
                    "update_frequency": "quarterly"
                }
            ]
            # å…¶ä»–é¢†åŸŸæ•°æ®æº...
        }
        
        return sources.get(self.domain, [])
    
    def connect_data_source(self, source_name):
        """è¿æ¥åˆ°æŒ‡å®šæ•°æ®æº"""
        # å®é™…å®ç°ä¸­è¿æ¥åˆ°çœŸå®æ•°æ®æº
        # æ­¤å¤„ç®€åŒ–å®ç°
        source = next((s for s in self.data_sources if s["name"] == source_name), None)
        if not source:
            return None
        
        print(f"è¿æ¥åˆ°æ•°æ®æº: {source_name} (ç±»å‹: {source['type']})")
        return {"status": "connected", "source": source}
    
    def query_data(self, source_name, query_params):
        """æŸ¥è¯¢æ•°æ®æºæ•°æ®"""
        # å®é™…å®ç°ä¸­æŸ¥è¯¢çœŸå®æ•°æ®
        # æ­¤å¤„ç®€åŒ–å®ç°
        return {"status": "success", "data": {"sample": "data"}}
```

### 5. å·¥å…·ä½¿ç”¨ä¼˜åŒ–

Agentä½¿ç”¨å·¥å…·çš„æ•ˆç‡å’Œå‡†ç¡®æ€§å¯¹å…¶æ•´ä½“æ€§èƒ½æœ‰é‡å¤§å½±å“ã€‚

#### 5.1 å·¥å…·é€‰æ‹©ä¸ç»„åˆ

ä¼˜åŒ–Agentå¯¹å·¥å…·çš„é€‰æ‹©å’Œç»„åˆèƒ½åŠ›ï¼š

**1. å·¥å…·åŠŸèƒ½åˆ†æ**

```python
def analyze_tool_capabilities(tools):
    """åˆ†æå·¥å…·é›†çš„åŠŸèƒ½è¦†ç›–å’Œé‡å """
    # æå–å·¥å…·åŠŸèƒ½
    capabilities = {}
    
    for tool in tools:
        # è·å–å·¥å…·èƒ½åŠ›å…³é”®è¯
        tool_caps = extract_capabilities(tool.description)
        
        for cap in tool_caps:
            if cap not in capabilities:
                capabilities[cap] = []
            capabilities[cap].append(tool.name)
    
    # åˆ†æç»“æœ
    results = {
        "total_tools": len(tools),
        "capability_coverage": list(capabilities.keys()),
        "overlapping_capabilities": {
            cap: tools for cap, tools in capabilities.items() if len(tools) > 1
        },
        "unique_capabilities": {
            cap: tools[0] for cap, tools in capabilities.items() if len(tools) == 1
        }
    }
    
    return results

def extract_capabilities(description):
    """ä»å·¥å…·æè¿°ä¸­æå–èƒ½åŠ›å…³é”®è¯"""
    # å®é™…å®ç°åº”ä½¿ç”¨NLPåˆ†æ
    # æ­¤å¤„ç®€åŒ–å®ç°ï¼Œå‡è®¾å…³é”®è¯å·²å­˜åœ¨
    keywords = description.lower().split()
    return [k for k in keywords if len(k) > 4]  # ç®€å•è¿‡æ»¤
```

**2. å·¥å…·ç»„åˆç­–ç•¥**

é’ˆå¯¹ä¸åŒä»»åŠ¡ç±»å‹é…ç½®æœ€ä½³å·¥å…·ç»„åˆï¼š

```python
class ToolSetOptimizer:
    def __init__(self, available_tools):
        """åˆå§‹åŒ–å·¥å…·é›†ä¼˜åŒ–å™¨"""
        self.available_tools = available_tools
        self.task_tool_mapping = self._build_task_mapping()
    
    def _build_task_mapping(self):
        """æ„å»ºä»»åŠ¡ç±»å‹åˆ°å·¥å…·çš„æ˜ å°„"""
        mapping = {
            "information_search": ["web_search", "database_query", "document_retriever"],
            "content_creation": ["text_generator", "image_creator", "code_writer"],
            "data_analysis": ["data_analyzer", "chart_creator", "statistical_tool"],
            "planning": ["task_planner", "scheduler", "priority_tool"],
            "communication": ["email_sender", "message_formatter", "translator"]
        }
        
        # è¿‡æ»¤åªä¿ç•™å¯ç”¨çš„å·¥å…·
        available_names = [tool.name for tool in self.available_tools]
        for task, tools in mapping.items():
            mapping[task] = [t for t in tools if t in available_names]
        
        return mapping
    
    def recommend_tools_for_task(self, task_description):
        """æ ¹æ®ä»»åŠ¡æè¿°æ¨èå·¥å…·ç»„åˆ"""
        # å®é™…å®ç°åº”ä½¿ç”¨ä»»åŠ¡åˆ†ç±»æˆ–ç›¸ä¼¼åº¦åŒ¹é…
        # æ­¤å¤„ç®€åŒ–å®ç°
        recommended_tools = []
        
        for task_type, tools in self.task_tool_mapping.items():
            if task_type.lower() in task_description.lower():
                recommended_tools.extend(tools)
        
        # ç§»é™¤é‡å¤é¡¹
        recommended_tools = list(set(recommended_tools))
        
        # è·å–å®é™…å·¥å…·å¯¹è±¡
        return [
            tool for tool in self.available_tools 
            if tool.name in recommended_tools
        ]
```

**3. å·¥å…·ä¾èµ–åˆ†æ**

åˆ†æå·¥å…·ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä¼˜åŒ–è°ƒç”¨é¡ºåºï¼š

```python
def analyze_tool_dependencies(tools):
    """åˆ†æå·¥å…·é—´çš„ä¾èµ–å…³ç³»"""
    # æ„å»ºä¾èµ–å›¾ï¼ˆç®€åŒ–å®ç°ï¼‰
    tool_map = {tool.name: tool for tool in tools}
    dependency_graph = {}
    
    for tool in tools:
        dependencies = []
        
        # æ£€æŸ¥è¯¥å·¥å…·çš„è¾“å…¥æ˜¯å¦ä¾èµ–å…¶ä»–å·¥å…·çš„è¾“å‡º
        for other in tools:
            if other.name != tool.name:
                if tool_depends_on(tool, other):
                    dependencies.append(other.name)
        
        dependency_graph[tool.name] = dependencies
    
    return dependency_graph

def tool_depends_on(tool1, tool2):
    """æ£€æŸ¥tool1æ˜¯å¦ä¾èµ–tool2çš„è¾“å‡º"""
    # å®é™…å®ç°åº”åˆ†æå‚æ•°å’Œè¿”å›å€¼ç±»å‹
    # æ­¤å¤„ä¸ºç®€åŒ–å®ç°ï¼Œè¿”å›å‡æ•°æ®
    return False  # æ ·ä¾‹è¿”å›
```

#### 5.2 å·¥å…·è°ƒç”¨æ•ˆç‡

æå‡Agentå¯¹å·¥å…·çš„è°ƒç”¨æ•ˆç‡ï¼š

**1. å‚æ•°ä¼ é€’ä¼˜åŒ–**

```python
def optimize_tool_parameters(tool, parameters, context):
    """ä¼˜åŒ–ä¼ é€’ç»™å·¥å…·çš„å‚æ•°"""
    optimized = parameters.copy()
    
    # æ£€æŸ¥å¿…è¦å‚æ•°
    required_params = get_required_parameters(tool)
    for param in required_params:
        if param not in optimized or not optimized[param]:
            # å°è¯•ä»ä¸Šä¸‹æ–‡ä¸­æå–
            optimized[param] = extract_from_context(param, context)
    
    # å»é™¤å†—ä½™å‚æ•°
    allowed_params = get_all_parameters(tool)
    for param in list(optimized.keys()):
        if param not in allowed_params:
            del optimized[param]
    
    # æ ¼å¼åŒ–å‚æ•°å€¼
    for param, value in optimized.items():
        param_type = get_parameter_type(tool, param)
        optimized[param] = format_parameter_value(value, param_type)
    
    return optimized

def extract_from_context(param_name, context):
    """ä»ä¸Šä¸‹æ–‡ä¸­æå–å‚æ•°å€¼"""
    # å®é™…å®ç°åº”ä½¿ç”¨æ›´å¤æ‚çš„ä¸Šä¸‹æ–‡åˆ†æ
    # æ­¤å¤„ç®€åŒ–å®ç°
    keywords = {
        "query": ["æœç´¢", "æŸ¥è¯¢", "å¯»æ‰¾", "æŸ¥æ‰¾"],
        "limit": ["é™åˆ¶", "æ•°é‡", "æ¡ç›®"],
        "start_date": ["å¼€å§‹æ—¥æœŸ", "ä»", "èµ·å§‹"],
        "end_date": ["ç»“æŸæ—¥æœŸ", "åˆ°", "æˆªæ­¢"]
    }
    
    if param_name in keywords:
        for keyword in keywords[param_name]:
            pattern = f"{keyword}[ï¼š:]*\\s*([\\w\\d\\-]+)"
            matches = re.findall(pattern, context)
            if matches:
                return matches[0]
    
    return None
```

**2. ç»“æœç¼“å­˜ç­–ç•¥**

ç¼“å­˜å·¥å…·è°ƒç”¨ç»“æœä»¥å‡å°‘é‡å¤è°ƒç”¨ï¼š

```python
class ToolResultCache:
    def __init__(self, cache_lifetime=3600):  # é»˜è®¤ç¼“å­˜1å°æ—¶
        """åˆå§‹åŒ–å·¥å…·ç»“æœç¼“å­˜"""
        self.cache = {}
        self.cache_lifetime = cache_lifetime  # ç¼“å­˜ç”Ÿå‘½å‘¨æœŸï¼ˆç§’ï¼‰
    
    def get(self, tool_name, parameters):
        """è·å–ç¼“å­˜çš„ç»“æœ"""
        cache_key = self._generate_key(tool_name, parameters)
        
        if cache_key in self.cache:
            entry = self.cache[cache_key]
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - entry["timestamp"] < self.cache_lifetime:
                entry["hits"] += 1
                return entry["result"]
            else:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                del self.cache[cache_key]
        
        return None
    
    def store(self, tool_name, parameters, result):
        """å­˜å‚¨å·¥å…·è°ƒç”¨ç»“æœ"""
        cache_key = self._generate_key(tool_name, parameters)
        
        self.cache[cache_key] = {
            "result": result,
            "timestamp": time.time(),
            "hits": 0
        }
    
    def _generate_key(self, tool_name, parameters):
        """ç”Ÿæˆç¼“å­˜é”®"""
        # å°†å‚æ•°è½¬æ¢ä¸ºå¯å“ˆå¸Œå½¢å¼
        param_str = json.dumps(parameters, sort_keys=True)
        return f"{tool_name}:{param_str}"
    
    def clear_expired(self):
        """æ¸…é™¤è¿‡æœŸç¼“å­˜"""
        now = time.time()
        expired_keys = [
            key for key, entry in self.cache.items()
            if now - entry["timestamp"] >= self.cache_lifetime
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        return len(expired_keys)
```

**3. å¹¶è¡Œè°ƒç”¨æŠ€æœ¯**

å®ç°å·¥å…·çš„å¹¶è¡Œè°ƒç”¨ä»¥æé«˜æ•´ä½“æ•ˆç‡ï¼š

```python
async def parallel_tool_execution(tools_with_params):
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨"""
    async def execute_tool(tool, params):
        try:
            result = await tool.arun(**params)
            return {
                "tool": tool.name,
                "success": True,
                "result": result,
                "error": None
            }
        except Exception as e:
            return {
                "tool": tool.name,
                "success": False,
                "result": None,
                "error": str(e)
            }
    
    # åˆ›å»ºæ‰€æœ‰å·¥å…·è°ƒç”¨çš„ä»»åŠ¡
    tasks = []
    for tool_data in tools_with_params:
        task = execute_tool(tool_data["tool"], tool_data["parameters"])
        tasks.append(task)
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks)
    return results
```

#### 5.3 å·¥å…·æè¿°ä¼˜åŒ–

ä¼˜åŒ–å·¥å…·æè¿°ä»¥å¸®åŠ©Agentæ›´å‡†ç¡®åœ°é€‰æ‹©å’Œä½¿ç”¨å·¥å…·ï¼š

**1. åŠŸèƒ½è¯´æ˜ç²¾ç¡®åŒ–**

```python
def optimize_tool_description(tool):
    """ä¼˜åŒ–å·¥å…·æè¿°"""
    # åŸå§‹æè¿°
    original_desc = tool.description
    
    # ç»“æ„åŒ–çš„æ”¹è¿›æè¿°
    improved_desc = f"""
{tool.name}: {get_concise_description(original_desc)}

ç”¨é€”: {get_purpose(original_desc)}

é€‚ç”¨åœºæ™¯: 
{get_use_cases(original_desc)}

è¾“å‡ºæ ¼å¼: 
{get_output_format(tool)}

æ³¨æ„äº‹é¡¹: 
{get_limitations(original_desc)}
""".strip()
    
    return improved_desc

def get_concise_description(desc):
    """æå–ç®€æ´æè¿°"""
    # å®é™…å®ç°åº”ä½¿ç”¨NLPæå–æ‘˜è¦
    # æ­¤å¤„ç®€åŒ–å®ç°
    first_sentence = desc.split('.')[0]
    return first_sentence if first_sentence else desc
```

**2. ä½¿ç”¨ç¤ºä¾‹å¢åŠ **

```python
def add_tool_examples(tool):
    """ä¸ºå·¥å…·æ·»åŠ ä½¿ç”¨ç¤ºä¾‹"""
    examples = []
    
    # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆç¤ºä¾‹ï¼ˆå®é™…å®ç°åº”æœ‰é¢„å®šä¹‰ç¤ºä¾‹åº“ï¼‰
    if "search" in tool.name.lower():
        examples.append({
            "description": "æœç´¢å…³äºæ°”å€™å˜åŒ–çš„æœ€æ–°ç ”ç©¶",
            "parameters": {"query": "æœ€æ–°æ°”å€™å˜åŒ–ç ”ç©¶", "limit": 5},
            "sample_output": "è¿”å›5ç¯‡å…³äºæ°”å€™å˜åŒ–çš„æœ€æ–°ç ”ç©¶æ–‡ç« ä¿¡æ¯..."
        })
    elif "analyze" in tool.name.lower():
        examples.append({
            "description": "åˆ†æå…¬å¸å­£åº¦é”€å”®æ•°æ®",
            "parameters": {"data_source": "sales_q2_2023.csv", "metrics": ["growth", "regions"]},
            "sample_output": "é”€å”®å¢é•¿åˆ†æç»“æœï¼ŒåŒ…æ‹¬åŒºåŸŸå¯¹æ¯”..."
        })
    # æ·»åŠ å…¶ä»–ç±»å‹çš„ç¤ºä¾‹...
    
    if not examples:
        # é€šç”¨ç¤ºä¾‹
        examples.append({
            "description": f"ä½¿ç”¨{tool.name}çš„åŸºæœ¬ç¤ºä¾‹",
            "parameters": {"param1": "value1"},
            "sample_output": "å·¥å…·æ‰§è¡Œç»“æœç¤ºä¾‹..."
        })
    
    # æ ¼å¼åŒ–ç¤ºä¾‹
    examples_text = "\nç¤ºä¾‹ç”¨æ³•:\n\n"
    for i, example in enumerate(examples, 1):
        examples_text += f"ç¤ºä¾‹{i}: {example['description']}\n"
        examples_text += f"å‚æ•°: {json.dumps(example['parameters'], ensure_ascii=False)}\n"
        examples_text += f"è¾“å‡º: {example['sample_output']}\n\n"
    
    return examples_text
```

### 6. ç”¨æˆ·ä½“éªŒä¸å®‰å…¨ä¼˜åŒ–

Agentä¸ç”¨æˆ·çš„äº¤äº’ä½“éªŒå’Œå®‰å…¨æ€§æ˜¯å…¶å®ç”¨ä»·å€¼çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

#### 6.1 äº¤äº’ä½“éªŒæ”¹è¿›

æå‡Agentä¸ç”¨æˆ·äº¤äº’çš„æµç•…æ€§å’Œå‹å¥½åº¦ï¼š

**1. å“åº”æ ¼å¼ä¼˜åŒ–**

```python
def optimize_response_format(response, user_preference=None):
    """ä¼˜åŒ–Agentå“åº”æ ¼å¼"""
    # é»˜è®¤æ ¼å¼åŒ–é€‰é¡¹
    format_options = {
        "use_markdown": True,
        "include_headings": True,
        "list_style": "bullet",
        "code_style": "block",
        "emphasis_style": "bold"
    }
    
    # åº”ç”¨ç”¨æˆ·åå¥½
    if user_preference:
        format_options.update(user_preference)
    
    # åº”ç”¨æ ¼å¼åŒ–ï¼ˆç®€åŒ–å®ç°ï¼‰
    formatted = response
    
    # æ·»åŠ Markdownæ ¼å¼
    if format_options["use_markdown"]:
        # è½¬æ¢åˆ—è¡¨
        if format_options["list_style"] == "bullet":
            formatted = re.sub(r'(?m)^(\d+)\.\s+(.*)', r'- \2', formatted)
        
        # æ·»åŠ ä»£ç å—æ ¼å¼
        if format_options["code_style"] == "block":
            formatted = re.sub(r'```(\w*)\n(.*?)\n```', r'```\1\n\2\n```', formatted, flags=re.DOTALL)
    
    return formatted
```

**2. è¿›åº¦åé¦ˆæœºåˆ¶**

```python
class ProgressTracker:
    def __init__(self, total_steps):
        """åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ªå™¨"""
        self.total_steps = total_steps
        self.completed_steps = 0
        self.current_step = None
        self.steps = []
        self.start_time = time.time()
        self.step_times = {}
    
    def set_steps(self, steps):
        """è®¾ç½®ä»»åŠ¡æ­¥éª¤"""
        self.steps = steps
        self.total_steps = len(steps)
    
    def start_step(self, step_name):
        """å¼€å§‹ä¸€ä¸ªæ­¥éª¤"""
        self.current_step = step_name
        self.step_times[step_name] = {
            "start": time.time(),
            "end": None,
            "duration": None
        }
        
        return self.get_progress_message()
    
    def complete_step(self, step_name=None):
        """å®Œæˆå½“å‰æ­¥éª¤"""
        step_to_complete = step_name or self.current_step
        
        if step_to_complete:
            self.completed_steps += 1
            self.step_times[step_to_complete]["end"] = time.time()
            self.step_times[step_to_complete]["duration"] = (
                self.step_times[step_to_complete]["end"] - 
                self.step_times[step_to_complete]["start"]
            )
        
        return self.get_progress_message()
    
    def get_progress_message(self):
        """è·å–è¿›åº¦æ¶ˆæ¯"""
        percent = (self.completed_steps / self.total_steps) * 100 if self.total_steps > 0 else 0
        
        message = f"è¿›åº¦: {self.completed_steps}/{self.total_steps} ({percent:.1f}%)"
        
        if self.current_step:
            message += f"\nå½“å‰æ­¥éª¤: {self.current_step}"
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        if self.completed_steps > 0:
            elapsed_time = time.time() - self.start_time
            time_per_step = elapsed_time / self.completed_steps
            remaining_steps = self.total_steps - self.completed_steps
            estimated_remaining = time_per_step * remaining_steps
            
            message += f"\né¢„è®¡å‰©ä½™æ—¶é—´: {format_time(estimated_remaining)}"
        
        return message

def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†é’Ÿ"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}å°æ—¶"
```

**3. é”™è¯¯ä¿¡æ¯å‹å¥½åŒ–**

```python
def user_friendly_error(error, context=None):
    """å°†æŠ€æœ¯é”™è¯¯è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„æ¶ˆæ¯"""
    error_messages = {
        "RateLimitError": {
            "message": "æˆ‘å¤„ç†è¯·æ±‚çš„é€Ÿåº¦éœ€è¦ç¨å¾®æ”¾æ…¢ä¸€äº›ã€‚è¯·ç¨ç­‰ç‰‡åˆ»å†ç»§ç»­ã€‚",
            "suggestion": "å¯ä»¥å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜ï¼Œæˆ–è€…ç¨åå†è¯•ã€‚"
        },
        "AuthenticationError": {
            "message": "ç³»ç»Ÿè®¿é—®æƒé™å‡ºç°äº†ä¸€ç‚¹é—®é¢˜ã€‚",
            "suggestion": "è¯·è”ç³»ç®¡ç†å‘˜ç¡®è®¤æ‚¨çš„è´¦å·è®¾ç½®æ­£ç¡®ã€‚"
        },
        "ServiceUnavailableError": {
            "message": "æœåŠ¡æš‚æ—¶æ— æ³•å“åº”ï¼Œè¿™å¯èƒ½æ˜¯ä¸´æ—¶æ€§çš„é—®é¢˜ã€‚",
            "suggestion": "è¯·ç¨åå†å°è¯•ï¼Œå¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ã€‚"
        },
        "InvalidRequestError": {
            "message": "æ‚¨çš„è¯·æ±‚åŒ…å«ä¸€äº›æˆ‘æ— æ³•å¤„ç†çš„å†…å®¹ã€‚",
            "suggestion": "è¯·å°è¯•é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ï¼Œç¡®ä¿æ‰€æœ‰å¿…è¦ä¿¡æ¯éƒ½å·²æä¾›ã€‚"
        },
        "APIConnectionError": {
            "message": "æˆ‘ç°åœ¨æ— æ³•è¿æ¥åˆ°éœ€è¦çš„æœåŠ¡ã€‚",
            "suggestion": "è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥ï¼Œæˆ–ç¨åå†è¯•ã€‚"
        },
        "ToolExecutionError": {
            "message": "æˆ‘åœ¨ä½¿ç”¨ç›¸å…³å·¥å…·æ—¶é‡åˆ°äº†é—®é¢˜ã€‚",
            "suggestion": "è¯·å°è¯•æä¾›æ›´æ¸…æ™°çš„æŒ‡ä»¤ï¼Œæˆ–ä½¿ç”¨å…¶ä»–æ–¹å¼å®ç°æ‚¨çš„ç›®æ ‡ã€‚"
        }
    }
    
    # æå–é”™è¯¯ç±»å‹
    error_type = type(error).__name__
    
    if error_type in error_messages:
        friendly = error_messages[error_type]
        return f"{friendly['message']} {friendly['suggestion']}"
    else:
        # é€šç”¨å‹å¥½é”™è¯¯æ¶ˆæ¯
        return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°æˆ–ç¨åå†è¯•ã€‚"
```

#### 6.2 å¯é æ€§å¢å¼º

æé«˜Agentåœ¨å„ç§æƒ…å†µä¸‹çš„ç¨³å®šæ€§ï¼š

**1. é”™è¯¯æ¢å¤ç­–ç•¥**

```python
class ResilientAgent:
    def __init__(self, base_agent, max_retries=3):
        """åˆå§‹åŒ–å¯é æ€§å¢å¼ºçš„Agent"""
        self.agent = base_agent
        self.max_retries = max_retries
        self.error_counters = {}
        self.recovery_strategies = self._setup_recovery()
    
    def _setup_recovery(self):
        """è®¾ç½®é”™è¯¯æ¢å¤ç­–ç•¥"""
        return {
            "RateLimitError": {
                "action": "wait_and_retry",
                "params": {"wait_time": 5, "backoff_factor": 2}
            },
            "APIConnectionError": {
                "action": "retry_with_backoff",
                "params": {"initial_wait": 1, "backoff_factor": 3, "max_wait": 15}
            },
            "ToolExecutionError": {
                "action": "try_alternative",
                "params": {"alternative_tools": ["fallback_tool_1", "fallback_tool_2"]}
            },
            "ContextLengthError": {
                "action": "reduce_context",
                "params": {"reduction_percent": 30}
            }
        }
    
    async def run(self, input_text):
        """æ‰§è¡ŒAgentæ“ä½œï¼ŒåŒ…å«é”™è¯¯æ¢å¤"""
        attempts = 0
        last_error = None
        
        while attempts < self.max_retries:
            try:
                result = await self.agent.arun(input_text)
                return result
            except Exception as e:
                attempts += 1
                last_error = e
                error_type = type(e).__name__
                
                # è®°å½•é”™è¯¯
                self.error_counters[error_type] = self.error_counters.get(error_type, 0) + 1
                
                # åº”ç”¨æ¢å¤ç­–ç•¥
                if error_type in self.recovery_strategies:
                    strategy = self.recovery_strategies[error_type]
                    
                    if strategy["action"] == "wait_and_retry":
                        wait_time = strategy["params"]["wait_time"]
                        backoff = strategy["params"]["backoff_factor"]
                        
                        # è®¡ç®—ç­‰å¾…æ—¶é—´
                        adjusted_wait = wait_time * (backoff ** (attempts - 1))
                        await asyncio.sleep(adjusted_wait)
                        continue
                        
                    elif strategy["action"] == "try_alternative":
                        # å°è¯•ä½¿ç”¨æ›¿ä»£å·¥å…·
                        alt_tools = strategy["params"]["alternative_tools"]
                        if attempts <= len(alt_tools):
                            # æ›´æ¢ä¸ºæ›¿ä»£å·¥å…·
                            alternative = alt_tools[attempts - 1]
                            input_text = f"ä½¿ç”¨{alternative}å·¥å…·: {input_text}"
                            continue
                
                # å¦‚æœæ²¡æœ‰æ¢å¤ç­–ç•¥æˆ–ç­–ç•¥å¤±è´¥ï¼Œç­‰å¾…çŸ­æš‚æ—¶é—´åé‡è¯•
                await asyncio.sleep(1 * attempts)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return user_friendly_error(last_error)
```

**2. ä¸ç¡®å®šæ€§ç®¡ç†**

```python
def handle_uncertainty(query, confidence_threshold=0.7):
    """å¤„ç†ä¸ç¡®å®šæ€§æƒ…å†µ"""
    # è¯„ä¼°å¯¹æŸ¥è¯¢çš„ç†è§£ç½®ä¿¡åº¦
    understanding_confidence = assess_understanding(query)
    
    if understanding_confidence < confidence_threshold:
        # è¯†åˆ«ä¸ç¡®å®šçš„éƒ¨åˆ†
        unclear_aspects = identify_unclear_aspects(query)
        
        if unclear_aspects:
            # ç”Ÿæˆæ¾„æ¸…é—®é¢˜
            clarification = generate_clarification_questions(unclear_aspects)
            return {
                "action": "seek_clarification",
                "message": clarification,
                "confidence": understanding_confidence,
                "unclear_aspects": unclear_aspects
            }
    
    # è¯„ä¼°å›ç­”ç½®ä¿¡åº¦
    answer_confidence = assess_answer_confidence(query)
    
    if answer_confidence < confidence_threshold:
        # æä¾›é€æ˜çš„ä½ç½®ä¿¡åº¦å›ç­”
        return {
            "action": "transparent_low_confidence",
            "message": f"ä»¥ä¸‹æ˜¯æˆ‘çš„å›ç­”ï¼Œä½†è¯·æ³¨æ„æˆ‘çš„æŠŠæ¡ä¸æ˜¯å¾ˆå¤§(çº¦{answer_confidence*100:.0f}%):",
            "confidence": answer_confidence
        }
    
    # æ­£å¸¸é«˜ç½®ä¿¡åº¦å›ç­”
    return {
        "action": "confident_response",
        "confidence": answer_confidence
    }

def assess_understanding(query):
    """è¯„ä¼°å¯¹æŸ¥è¯¢çš„ç†è§£ç½®ä¿¡åº¦"""
    # å®é™…å®ç°åº”åŸºäºæŸ¥è¯¢åˆ†æ
    # æ­¤å¤„ç®€åŒ–å®ç°
    ambiguous_terms = ["å¯èƒ½", "æˆ–è®¸", "ä¹Ÿè®¸", "æœ‰æ—¶", "ä¸ç¡®å®š"]
    vague_terms = ["ä¸€äº›", "å¾ˆå¤š", "å¤§æ¦‚", "æŸç§", "æŸäº›"]
    
    # æ£€æŸ¥æ¨¡ç³Šè¯æ±‡å‡ºç°ç‡
    ambiguity_score = sum(term in query for term in ambiguous_terms) * 0.1
    vagueness_score = sum(term in query for term in vague_terms) * 0.1
    
    base_confidence = 0.9  # åŸºç¡€ç½®ä¿¡åº¦
    final_confidence = base_confidence - ambiguity_score - vagueness_score
    
    return max(0.3, min(final_confidence, 1.0))  # çº¦æŸåœ¨0.3-1.0èŒƒå›´
```

#### 6.3 å®‰å…¨ä¸ä¼¦ç†æ§åˆ¶

å¢å¼ºAgentçš„å®‰å…¨æ€§å’Œåˆè§„æ€§ï¼š

**1. è¾“å…¥è¿‡æ»¤æœºåˆ¶**

```python
def safety_filter_input(user_input):
    """è¿‡æ»¤ç”¨æˆ·è¾“å…¥ä¸­çš„æ½œåœ¨é£é™©å†…å®¹"""
    # å®šä¹‰æ•æ„Ÿå†…å®¹ç±»åˆ«
    sensitive_categories = {
        "harmful_instructions": [
            "ç¼–å†™æ¶æ„ä»£ç ", "é»‘å®¢æ”»å‡»", "ç»•è¿‡å®‰å…¨", "ç ´è§£å¯†ç "
        ],
        "illegal_activities": [
            "åˆ¶ä½œéæ³•ç‰©å“", "é€ƒç¨æ–¹æ³•", "ç›—çªƒæŠ€å·§", "ä¼ªé€ æ–‡ä»¶"
        ],
        "personal_identification": [
            "èº«ä»½è¯å·ç ", "ä¿¡ç”¨å¡å·", "é“¶è¡Œè´¦å·", "å¯†ç "
        ],
        "hate_speech": [
            # ä»‡æ¨è¨€è®ºå…³é”®è¯
        ]
    }
    
    # æ£€æŸ¥æ•æ„Ÿå†…å®¹
    detected_categories = []
    
    for category, keywords in sensitive_categories.items():
        for keyword in keywords:
            if keyword in user_input.lower():
                detected_categories.append(category)
                break
    
    if detected_categories:
        return {
            "filtered": True,
            "categories": detected_categories,
            "message": "æ‚¨çš„è¯·æ±‚åŒ…å«æ— æ³•å¤„ç†çš„å†…å®¹ã€‚è¯·ä¿®æ”¹æ‚¨çš„è¯·æ±‚ï¼Œé¿å…æ•æ„Ÿæˆ–ä¸å½“å†…å®¹ã€‚"
        }
    
    return {
        "filtered": False,
        "input": user_input
    }
```

**2. è¾“å‡ºå®¡æŸ¥æœºåˆ¶**

```python
def safety_check_output(response):
    """å®¡æŸ¥Agentè¾“å‡ºå†…å®¹çš„å®‰å…¨æ€§"""
    # å®šä¹‰æ½œåœ¨é—®é¢˜æ¨¡å¼
    problematic_patterns = {
        "unsafe_code": r"rm\s+-rf|system\(|exec\(|eval\(|sudo|chmod\s+777",
        "harmful_instructions": r"å¦‚ä½•é»‘å®¢|å¦‚ä½•ç»•è¿‡|å¦‚ä½•å…¥ä¾µ|ç ´è§£å¯†ç ",
        "excessive_disclosure": r"å®Œæ•´ä»£ç å¦‚ä¸‹|ä½¿ç”¨è¿™ä¸ªæ¼æ´|ç»•è¿‡é™åˆ¶çš„æ–¹æ³•",
        "misleading_claims": r"ç™¾åˆ†ç™¾æœ‰æ•ˆ|ç»å¯¹å®‰å…¨|å®Œå…¨åŒ¿å|æ— æ³•è¿½è¸ª"
    }
    
    # æ£€æŸ¥æ¨¡å¼åŒ¹é…
    detected_issues = {}
    
    for issue, pattern in problematic_patterns.items():
        if re.search(pattern, response, re.IGNORECASE):
            detected_issues[issue] = True
    
    if detected_issues:
        # åº”ç”¨ç¼“è§£ç­–ç•¥
        mitigated_response = mitigate_safety_issues(response, detected_issues)
        
        return {
            "original": response,
            "issues_detected": detected_issues,
            "mitigated": mitigated_response,
            "modified": True
        }
    
    return {
        "original": response,
        "modified": False
    }

def mitigate_safety_issues(response, issues):
    """ç¼“è§£æ£€æµ‹åˆ°çš„å®‰å…¨é—®é¢˜"""
    mitigated = response
    
    if "unsafe_code" in issues:
        # æ›¿æ¢ä¸å®‰å…¨ä»£ç 
        mitigated = re.sub(
            r"(rm\s+-rf|system\(|exec\(|eval\(|sudo|chmod\s+777)",
            "[ä¸å®‰å…¨çš„ä»£ç å·²ç§»é™¤]",
            mitigated
        )
    
    if "harmful_instructions" in issues:
        # æ·»åŠ è­¦å‘Šä¿¡æ¯
        mitigated = "è¯·æ³¨æ„ï¼šä»¥ä¸‹å›ç­”ä»…ä¾›æ•™è‚²ç›®çš„ï¼Œä¸åº”ç”¨äºä»»ä½•å¯èƒ½é€ æˆæŸå®³çš„æ´»åŠ¨ã€‚\n\n" + mitigated
    
    if "excessive_disclosure" in issues:
        # æ¨¡ç³ŠåŒ–è¿‡äºè¯¦ç»†çš„æŒ‡å¯¼
        mitigated = re.sub(
            r"(å®Œæ•´ä»£ç å¦‚ä¸‹|ä½¿ç”¨è¿™ä¸ªæ¼æ´|ç»•è¿‡é™åˆ¶çš„æ–¹æ³•)",
            "ä¸ºäº†å®‰å…¨è€ƒè™‘ï¼Œæ— æ³•æä¾›è¯¦ç»†æŒ‡å—ã€‚",
            mitigated
        )
    
    return mitigated
```

**3. éšç§ä¿æŠ¤æªæ–½**

```python
def privacy_protection(text, level="medium"):
    """åº”ç”¨éšç§ä¿æŠ¤æªæ–½"""
    # å®šä¹‰æ•æ„Ÿæ•°æ®æ¨¡å¼
    sensitive_patterns = {
        "email": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
        "phone": r'\b(?:\+?86)?1[3-9]\d{9}\b',
        "id_card": r'\b[1-9]\d{5}(?:19|20)\d{2}(?:0[1-9]|1[0-2])(?:0[1-9]|[12]\d|3[01])\d{3}[\dXx]\b',
        "address": r'\b(?:åŒ—äº¬|ä¸Šæµ·|å¹¿å·|æ·±åœ³|å¤©æ´¥|é‡åº†|æˆéƒ½|æ­¦æ±‰|è¥¿å®‰|å—äº¬)å¸‚[\w\s\dè·¯è¡—é“å·å®¤]{5,30}\b',
        "financial": r'\b(?:6\d{15}|4\d{15}|5[1-5]\d{14})\b'  # ç®€åŒ–çš„ä¿¡ç”¨å¡æ ¼å¼
    }
    
    # æ ¹æ®ä¿æŠ¤çº§åˆ«é€‰æ‹©å¤„ç†æ–¹å¼
    if level == "high":
        # é«˜çº§ä¿æŠ¤ï¼šç§»é™¤æ‰€æœ‰å¯èƒ½çš„æ•æ„Ÿä¿¡æ¯
        for pattern_name, pattern in sensitive_patterns.items():
            text = re.sub(pattern, f"[{pattern_name}_å·²ä¿æŠ¤]", text)
    
    elif level == "medium":
        # ä¸­çº§ä¿æŠ¤ï¼šéƒ¨åˆ†éšè—
        text = re.sub(sensitive_patterns["email"], 
                      lambda m: m.group(0).split('@')[0][:3] + "***@" + m.group(0).split('@')[1], text)
        
        text = re.sub(sensitive_patterns["phone"], 
                      lambda m: m.group(0)[:3] + "****" + m.group(0)[-4:], text)
        
        text = re.sub(sensitive_patterns["id_card"], 
                      lambda m: m.group(0)[:6] + "********" + m.group(0)[-4:], text)
    
    elif level == "low":
        # ä½çº§ä¿æŠ¤ï¼šä»…å¤„ç†æœ€æ•æ„Ÿä¿¡æ¯
        text = re.sub(sensitive_patterns["id_card"], 
                      lambda m: m.group(0)[:6] + "********" + m.group(0)[-4:], text)
        
        text = re.sub(sensitive_patterns["financial"], 
                      lambda m: m.group(0)[:4] + " **** **** " + m.group(0)[-4:], text)
    
    return text
```

## ğŸ’» å®è·µæ´»åŠ¨ä¸ä»£ç ç¤ºä¾‹

è®©æˆ‘ä»¬é€šè¿‡å®é™…æ¡ˆä¾‹æ¥ç»ƒä¹ Agentä¼˜åŒ–çš„å…³é”®æŠ€æœ¯ã€‚

### å®è·µ1ï¼šAgentæ€§èƒ½è¯„ä¼°ä¸æ”¹è¿›

åœ¨æœ¬å®è·µä¸­ï¼Œæˆ‘ä»¬å°†è¯„ä¼°ä¸€ä¸ªç®€å•AI Agentçš„æ€§èƒ½ï¼Œå¹¶åº”ç”¨å‰é¢å­¦ä¹ çš„ä¼˜åŒ–æŠ€æœ¯è¿›è¡Œæ”¹è¿›ã€‚

**æ­¥éª¤1ï¼šåˆ›å»ºåŸºç¡€Agent**

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªåŸºç¡€Agentä½œä¸ºä¼˜åŒ–çš„èµ·ç‚¹ï¼š

```python
from langchain.llms import OpenAI
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.prompts import StringPromptTemplate
from langchain.chains import LLMChain

# ç®€å•å·¥å…·å®šä¹‰
tools = [
    Tool(
        name="æœç´¢",
        func=lambda query: f"æœç´¢ç»“æœ: å…³äº'{query}'çš„ä¿¡æ¯...",
        description="ç”¨äºæœç´¢ä¿¡æ¯çš„å·¥å…·"
    ),
    Tool(
        name="è®¡ç®—å™¨",
        func=lambda expression: f"è®¡ç®—ç»“æœ: {eval(expression)}",
        description="ç”¨äºæ‰§è¡Œæ•°å­¦è®¡ç®—"
    )
]

# åˆ›å»ºåŸºç¡€Agent
llm = OpenAI(temperature=0)
agent = initialize_agent(
    tools, 
    llm, 
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
```

**æ­¥éª¤2ï¼šå®šä¹‰è¯„ä¼°æŒ‡æ ‡å’Œæµ‹è¯•ç”¨ä¾‹**

```python
# å®šä¹‰æµ‹è¯•ç”¨ä¾‹
test_cases = [
    {
        "id": "fact_query",
        "input": "æ°´çš„åŒ–å­¦å¼æ˜¯ä»€ä¹ˆï¼Ÿ",
        "expected_tool": "æœç´¢",
        "complexity": "low"
    },
    {
        "id": "math_problem",
        "input": "è®¡ç®—15*27çš„ç»“æœ",
        "expected_tool": "è®¡ç®—å™¨",
        "complexity": "low" 
    },
    {
        "id": "mixed_task",
        "input": "å¤ªé˜³ç³»æœ‰å¤šå°‘é¢—è¡Œæ˜Ÿï¼Ÿç„¶åè®¡ç®—è¿™ä¸ªæ•°å­—çš„å¹³æ–¹",
        "expected_tools": ["æœç´¢", "è®¡ç®—å™¨"],
        "complexity": "medium"
    }
]

# å®šä¹‰è¯„ä¼°å‡½æ•°
def evaluate_agent(agent, test_cases):
    results = {}
    
    for test in test_cases:
        start_time = time.time()
        try:
            response = agent.run(test["input"])
            success = True
            error = None
        except Exception as e:
            response = None
            success = False
            error = str(e)
        
        end_time = time.time()
        
        # è®°å½•ç»“æœ
        results[test["id"]] = {
            "success": success,
            "response": response,
            "error": error,
            "response_time": end_time - start_time
        }
        
        # åˆ†æå·¥å…·ä½¿ç”¨
        if success and "expected_tool" in test:
            tool_correct = test["expected_tool"] in response
            results[test["id"]]["tool_correct"] = tool_correct
    
    return results
```

**æ­¥éª¤3ï¼šæ‰§è¡ŒåŸºå‡†è¯„ä¼°**

```python
# è¯„ä¼°åŸºç¡€Agent
baseline_results = evaluate_agent(agent, test_cases)

# æ‰“å°è¯„ä¼°ç»“æœ
print("åŸºç¡€Agentè¯„ä¼°ç»“æœ:")
for test_id, result in baseline_results.items():
    print(f"æµ‹è¯•: {test_id}")
    print(f"  æˆåŠŸ: {result['success']}")
    print(f"  å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")
    if "tool_correct" in result:
        print(f"  å·¥å…·é€‰æ‹©æ­£ç¡®: {result['tool_correct']}")
    print("")
```

**æ­¥éª¤4ï¼šä¼˜åŒ–Agentæç¤ºè¯**

```python
# è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
class CustomPromptTemplate(StringPromptTemplate):
    template: str
    tools: list
    
    def format(self, **kwargs):
        # è·å–ä¸­é—´å˜é‡
        intermediate_steps = kwargs.pop("intermediate_steps")
        thoughts = ""
        
        # å¢å¼ºæç¤ºè¯ç»“æ„
        for action, observation in intermediate_steps:
            thoughts += f"è¡ŒåŠ¨: {action.log}\n"
            thoughts += f"è§‚å¯Ÿ: {observation}\n"
        
        # å·¥å…·æè¿°ä¼˜åŒ–
        tools_description = ""
        for tool in self.tools:
            tools_description += f"{tool.name}: {tool.description}\n"
        
        # ä½¿ç”¨ä¼˜åŒ–çš„æç¤ºè¯æ¨¡æ¿
        kwargs["agent_scratchpad"] = thoughts
        kwargs["tools"] = tools_description
        kwargs["tool_names"] = ", ".join([tool.name for tool in self.tools])
        
        # æ‰©å±•æç¤ºè¯
        prompt = self.template.format(**kwargs)
        
        return prompt

# å¢å¼ºçš„æç¤ºè¯æ¨¡æ¿
optimized_template = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿåˆ©ç”¨å·¥å…·è§£å†³å„ç§é—®é¢˜ã€‚

å¯ç”¨å·¥å…·:
{tools}

æ‰§è¡Œä»»åŠ¡æ—¶è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤:
1. ç†è§£ç”¨æˆ·éœ€æ±‚
2. ç¡®å®šéœ€è¦ä½¿ç”¨çš„å·¥å…·
3. ä½¿ç”¨å·¥å…·è·å–ä¿¡æ¯æˆ–æ‰§è¡Œæ“ä½œ
4. ç»™å‡ºæ¸…æ™°çš„æœ€ç»ˆç­”æ¡ˆ

ç”¨æˆ·é—®é¢˜: {input}

{agent_scratchpad}

æ€è€ƒä½ çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
ä½¿ç”¨æ ¼å¼:
æ€è€ƒ: åˆ†æé—®é¢˜å’Œè€ƒè™‘ä½¿ç”¨å“ªä¸ªå·¥å…·
è¡ŒåŠ¨: å·¥å…·å[å·¥å…·è¾“å…¥]
è§‚å¯Ÿ: å·¥å…·è¿”å›çš„ç»“æœ
... (å¯é‡å¤ä»¥ä¸Šæ­¥éª¤)
å›ç­”: ç»™ç”¨æˆ·çš„æœ€ç»ˆå›ç­”
"""

# åˆ›å»ºä¼˜åŒ–Agent
optimized_prompt = CustomPromptTemplate(
    template=optimized_template,
    tools=tools,
    input_variables=["input", "intermediate_steps"]
)

# ä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯é‡æ–°åˆå§‹åŒ–Agent
from langchain.agents import AgentExecutor, LLMSingleActionAgent

llm_chain = LLMChain(llm=llm, prompt=optimized_prompt)
optimized_agent = LLMSingleActionAgent(
    llm_chain=llm_chain,
    output_parser=agent.agent.output_parser,
    stop=["\nObservation:"],
    allowed_tools=[tool.name for tool in tools]
)

optimized_agent_executor = AgentExecutor.from_agent_and_tools(
    agent=optimized_agent,
    tools=tools,
    verbose=True
)
```

**æ­¥éª¤5ï¼šæ¯”è¾ƒä¼˜åŒ–å‰åçš„æ€§èƒ½**

```python
# è¯„ä¼°ä¼˜åŒ–åçš„Agent
optimized_results = evaluate_agent(optimized_agent_executor, test_cases)

# æ¯”è¾ƒç»“æœ
print("æ€§èƒ½å¯¹æ¯”:")
for test_id in baseline_results.keys():
    baseline = baseline_results[test_id]
    optimized = optimized_results[test_id]
    
    time_diff = baseline["response_time"] - optimized["response_time"]
    time_improvement = (time_diff / baseline["response_time"]) * 100
    
    print(f"æµ‹è¯•: {test_id}")
    print(f"  å“åº”æ—¶é—´æ”¹è¿›: {time_improvement:.2f}%")
    print(f"  åŸºå‡†: {baseline['response_time']:.2f}ç§’ -> ä¼˜åŒ–å: {optimized['response_time']:.2f}ç§’")
    
    if "tool_correct" in baseline and "tool_correct" in optimized:
        print(f"  å·¥å…·é€‰æ‹©: {'æ”¹è¿›' if optimized['tool_correct'] and not baseline['tool_correct'] else 'æ— å˜åŒ–' if optimized['tool_correct'] == baseline['tool_correct'] else 'å˜å·®'}")
    
    print("")
```

### å®è·µ2ï¼šä¸“ä¸šé¢†åŸŸAgentå®šåˆ¶

åœ¨è¿™ä¸ªå®è·µä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä¸“é—¨ç”¨äºæ³•å¾‹å’¨è¯¢çš„ä¸“ä¸šé¢†åŸŸAgentã€‚

**æ­¥éª¤1ï¼šæ”¶é›†é¢†åŸŸçŸ¥è¯†**

```python
# æ³•å¾‹é¢†åŸŸçŸ¥è¯†ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
legal_terminology = {
    "åˆåŒ": "å…·æœ‰æ³•å¾‹çº¦æŸåŠ›çš„åŒæ–¹æˆ–å¤šæ–¹å½“äº‹äººä¹‹é—´çš„çº¦å®š",
    "ä¾µæƒ": "è¿åæ³•å®šä¹‰åŠ¡æˆ–ä¾µçŠ¯ä»–äººåˆæ³•æƒç›Šçš„è¡Œä¸º",
    "è¯‰è®¼æ—¶æ•ˆ": "æ³•å¾‹è§„å®šçš„æƒåˆ©äººå¯ä»¥å‘æ³•é™¢è¯·æ±‚ä¿æŠ¤æ°‘äº‹æƒåˆ©çš„æœŸé™",
    "ä¸å¯æŠ—åŠ›": "ä¸èƒ½é¢„è§ã€ä¸èƒ½é¿å…ä¸”ä¸èƒ½å…‹æœçš„å®¢è§‚æƒ…å†µ",
    "è¿çº¦é‡‘": "åˆåŒå½“äº‹äººçº¦å®šçš„åœ¨è¿çº¦æƒ…å†µä¸‹åº”å½“æ”¯ä»˜çš„é‡‘é’±èµ”å¿"
}

legal_principles = [
    "åˆåŒè‡ªç”±åŸåˆ™ï¼šå½“äº‹äººåœ¨æ³•å¾‹å…è®¸èŒƒå›´å†…è‡ªç”±è®¢ç«‹åˆåŒ",
    "è¯šå®ä¿¡ç”¨åŸåˆ™ï¼šæ°‘äº‹ä¸»ä½“ä»äº‹æ°‘äº‹æ´»åŠ¨åº”å½“éµå¾ªè¯šå®ä¿¡ç”¨",
    "å…¬å¹³åŸåˆ™ï¼šç¡®å®šæ°‘äº‹æƒåˆ©ä¹‰åŠ¡åº”å½“å…¬å¹³ï¼Œæƒåˆ©ä¹‰åŠ¡ç›¸ä¸€è‡´",
    "ç¦æ­¢æƒåˆ©æ»¥ç”¨åŸåˆ™ï¼šè¡Œä½¿æƒåˆ©ä¸å¾—æŸå®³å›½å®¶ã€é›†ä½“æˆ–ä»–äººåˆ©ç›Š"
]

common_legal_questions = [
    {"question": "ä»€ä¹ˆæ˜¯åˆåŒè¿çº¦ï¼Ÿ", "answer": "åˆåŒè¿çº¦æ˜¯æŒ‡åˆåŒå½“äº‹äººä¸å±¥è¡ŒåˆåŒä¹‰åŠ¡æˆ–è€…å±¥è¡Œä¸ç¬¦åˆçº¦å®šçš„è¡Œä¸ºã€‚"},
    {"question": "ç§Ÿæˆ¿åˆåŒåˆ°æœŸæˆ¿ä¸œä¸é€€æŠ¼é‡‘æ€ä¹ˆåŠï¼Ÿ", "answer": "å¯ä»¥å…ˆä¸æˆ¿ä¸œåå•†ï¼Œåå•†ä¸æˆå¯ä»¥ç”³è¯·è°ƒè§£æˆ–æèµ·è¯‰è®¼ï¼Œå¹¶æä¾›ç›¸å…³è¯æ®å¦‚åˆåŒã€æ”¯ä»˜å‡­è¯ç­‰ã€‚"}
]
```

**æ­¥éª¤2ï¼šåˆ›å»ºä¸“ä¸šçŸ¥è¯†åº“**

```python
from langchain.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.embeddings import OpenAIEmbeddings

# åˆ›å»ºæ³•å¾‹çŸ¥è¯†æ–‡æ¡£
legal_documents = []

# æ·»åŠ æœ¯è¯­è§£é‡Š
for term, definition in legal_terminology.items():
    doc = Document(
        page_content=f"æœ¯è¯­: {term}\nå®šä¹‰: {definition}",
        metadata={"source": "legal_terminology", "term": term}
    )
    legal_documents.append(doc)

# æ·»åŠ æ³•å¾‹åŸåˆ™
for principle in legal_principles:
    doc = Document(
        page_content=f"æ³•å¾‹åŸåˆ™: {principle}",
        metadata={"source": "legal_principles"}
    )
    legal_documents.append(doc)

# æ·»åŠ å¸¸è§é—®é¢˜
for qa in common_legal_questions:
    doc = Document(
        page_content=f"é—®é¢˜: {qa['question']}\nå›ç­”: {qa['answer']}",
        metadata={"source": "common_questions"}
    )
    legal_documents.append(doc)

# åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vector_store = FAISS.from_documents(legal_documents, embeddings)

# åˆ›å»ºæ£€ç´¢å·¥å…·
legal_knowledge_tool = Tool(
    name="æ³•å¾‹çŸ¥è¯†åº“",
    func=lambda q: vector_store.similarity_search(q, k=2),
    description="ç”¨äºæŸ¥è¯¢æ³•å¾‹æœ¯è¯­ã€åŸåˆ™å’Œå¸¸è§é—®é¢˜çš„å·¥å…·"
)
```

**æ­¥éª¤3ï¼šå®šåˆ¶æ³•å¾‹ä¸“å®¶Agent**

```python
# æ³•å¾‹ä¸“å®¶ç³»ç»Ÿæç¤º
legal_expert_prompt = """ä½ æ˜¯ä¸€ä½æ‹¥æœ‰å¤šå¹´ç»éªŒçš„æ³•å¾‹é¡¾é—®ï¼Œä¸“é•¿äºåˆåŒæ³•ã€æ°‘æ³•å’Œæ¶ˆè´¹è€…æƒç›Šä¿æŠ¤ã€‚

ä½ çš„å·¥ä½œå‡†åˆ™:
1. å§‹ç»ˆåŸºäºæ³•å¾‹äº‹å®æä¾›å»ºè®®ï¼Œä¸æºæ‚ä¸ªäººè§‚ç‚¹
2. å¼•ç”¨ç›¸å…³æ³•å¾‹æ¡æ¬¾æ”¯æŒä½ çš„åˆ†æ
3. æ˜ç¡®åŒºåˆ†æ³•å¾‹äº‹å®å’Œä¸ªäººæ„è§
4. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€è¡¨è¾¾æ³•å¾‹æ¦‚å¿µ
5. å½“é—®é¢˜è¶…å‡ºä½ çš„ä¸“ä¸šèŒƒå›´æ—¶ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·

åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹ç»“æ„:
1. æ³•å¾‹é—®é¢˜åˆ†æ: æ˜ç¡®è¯†åˆ«æ¶‰åŠçš„æ³•å¾‹é—®é¢˜
2. é€‚ç”¨æ³•å¾‹è§„å®š: æŒ‡å‡ºç›¸å…³æ³•å¾‹æ¡æ¬¾
3. æ³•å¾‹åˆ†æ: å°†æ³•å¾‹åº”ç”¨äºå…·ä½“æƒ…å†µ
4. å»ºè®®: æä¾›å¯è¡Œçš„è§£å†³æ–¹æ¡ˆ
5. æ³¨æ„äº‹é¡¹: æŒ‡å‡ºéœ€è¦æ³¨æ„çš„é£é™©æˆ–é™åˆ¶

è¯·è®°ä½ï¼Œä½ çš„å»ºè®®ä¸æ„æˆæ­£å¼æ³•å¾‹æ„è§ï¼Œå¤æ‚é—®é¢˜åº”å»ºè®®ç”¨æˆ·å’¨è¯¢æ‰§ä¸šå¾‹å¸ˆã€‚

å¯ç”¨å·¥å…·:
{tools}

ç”¨æˆ·é—®é¢˜: {input}

{agent_scratchpad}
"""

# åˆ›å»ºæ³•å¾‹ä¸“å®¶Agent
legal_expert_prompt_template = CustomPromptTemplate(
    template=legal_expert_prompt,
    tools=[legal_knowledge_tool],
    input_variables=["input", "intermediate_steps"]
)

legal_llm_chain = LLMChain(llm=llm, prompt=legal_expert_prompt_template)
legal_expert_agent = LLMSingleActionAgent(
    llm_chain=legal_llm_chain,
    output_parser=agent.agent.output_parser,
    stop=["\nObservation:"],
    allowed_tools=[legal_knowledge_tool.name]
)

legal_expert = AgentExecutor.from_agent_and_tools(
    agent=legal_expert_agent,
    tools=[legal_knowledge_tool],
    verbose=True
)
```

**æ­¥éª¤4ï¼šæµ‹è¯•æ³•å¾‹ä¸“å®¶Agent**

```python
# æµ‹è¯•æ¡ˆä¾‹
legal_test_cases = [
    "æˆ‘ç­¾äº†ä¸€ä»½ç§Ÿæˆ¿åˆåŒï¼Œä½†æˆ¿ä¸œç°åœ¨è¦æå‰ç»ˆæ­¢ï¼Œæˆ‘æœ‰ä»€ä¹ˆæƒåˆ©ï¼Ÿ",
    "æ¶ˆè´¹è€…åœ¨ç½‘è´­å•†å“åå‘ç°è´¨é‡é—®é¢˜ï¼Œé€€è´§è¢«æ‹’ï¼Œå¦‚ä½•ç»´æƒï¼Ÿ",
    "ä»€ä¹ˆæ˜¯ä¸å¯æŠ—åŠ›ï¼Ÿå®ƒå¯¹åˆåŒå±¥è¡Œæœ‰ä»€ä¹ˆå½±å“ï¼Ÿ"
]

# æ‰§è¡Œæµ‹è¯•
for i, test in enumerate(legal_test_cases, 1):
    print(f"æµ‹è¯• {i}: {test}")
    try:
        response = legal_expert.run(test)
        print(f"å›ç­”: {response}\n")
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}\n")
```

### å®è·µ3ï¼šè®°å¿†ç³»ç»Ÿå®ç°

è¿™ä¸ªå®è·µä¸­ï¼Œæˆ‘ä»¬å°†ä¸ºAgentå®ç°ä¸€ä¸ªç®€å•çš„è®°å¿†ç³»ç»Ÿï¼Œä½¿å…¶èƒ½å¤Ÿä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚

**æ­¥éª¤1ï¼šå®ç°ä¼šè¯è®°å¿†**

```python
from langchain.memory import ConversationBufferMemory

# åˆ›å»ºåŸºæœ¬è®°å¿†
memory = ConversationBufferMemory(return_messages=True)

# åˆå§‹åŒ–ä¸€äº›å¯¹è¯å†å²
memory.chat_memory.add_user_message("æˆ‘å«å¼ ä¸‰ï¼Œä»Šå¹´35å²")
memory.chat_memory.add_ai_message("ä½ å¥½å¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘èƒ½å¸®åŠ©ä½ çš„å—ï¼Ÿ")
memory.chat_memory.add_user_message("æˆ‘æœ‰ä¸€ä¸ªå…³äºåˆåŒæ³•çš„é—®é¢˜")
memory.chat_memory.add_ai_message("å½“ç„¶ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›æ³•å¾‹æ–¹é¢çš„å¸®åŠ©ã€‚")
```

**æ­¥éª¤2ï¼šå®ç°è‡ªå®šä¹‰è®°å¿†ç®¡ç†**

```python
class EnhancedConversationMemory:
    def __init__(self, max_history=10):
        self.messages = []
        self.max_history = max_history
        self.user_info = {}
        self.conversation_summary = ""
        self.important_points = []
    
    def add_message(self, role, content):
        # æ·»åŠ æ–°æ¶ˆæ¯
        self.messages.append({"role": role, "content": content})
        
        # å¦‚æœè¶…å‡ºå†å²é™åˆ¶ï¼Œè¿›è¡Œå‹ç¼©
        if len(self.messages) > self.max_history:
            self._compress_history()
        
        # ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–ä¿¡æ¯
        if role == "user":
            self._extract_user_info(content)
            self._identify_important_points(content)
    
    def _compress_history(self):
        # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯ï¼Œæœ€æ—§çš„æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦
        oldest_messages = self.messages[:2]  # å–æœ€æ—§çš„ä¸¤æ¡
        self.messages = self.messages[2:]  # ç§»é™¤æœ€æ—§çš„ä¸¤æ¡
        
        # ç”Ÿæˆæ‘˜è¦ï¼ˆå®é™…åº”ç”¨ä¸­ä½¿ç”¨LLMç”Ÿæˆï¼‰
        summary = f"ä¹‹å‰çš„å¯¹è¯ï¼šç”¨æˆ·æåˆ° {oldest_messages[0]['content'][:30]}..."
        self.conversation_summary = summary
        
        # åœ¨æ¶ˆæ¯åˆ—è¡¨å¼€å¤´æ·»åŠ æ‘˜è¦
        self.messages.insert(0, {"role": "system", "content": summary})
    
    def _extract_user_info(self, message):
        # æå–ç”¨æˆ·ä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰
        name_match = re.search(r"æˆ‘å«\s*(\w+)", message)
        if name_match:
            self.user_info["name"] = name_match.group(1)
        
        age_match = re.search(r"(\d+)\s*å²", message)
        if age_match:
            self.user_info["age"] = int(age_match.group(1))
    
    def _identify_important_points(self, message):
        # è¯†åˆ«é‡è¦ä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰
        if "è®°ä½" in message or "é‡è¦" in message or "ä¸è¦å¿˜è®°" in message:
            self.important_points.append(message)
    
    def get_context_for_llm(self):
        """è·å–ç”¨äºLLMçš„ä¸Šä¸‹æ–‡"""
        context = ""
        
        # æ·»åŠ ç”¨æˆ·ä¿¡æ¯
        if self.user_info:
            context += "ç”¨æˆ·ä¿¡æ¯:\n"
            for key, value in self.user_info.items():
                context += f"- {key}: {value}\n"
            context += "\n"
        
        # æ·»åŠ é‡è¦ç‚¹
        if self.important_points:
            context += "é‡è¦ä¿¡æ¯:\n"
            for point in self.important_points:
                context += f"- {point}\n"
            context += "\n"
        
        # æ·»åŠ å¯¹è¯å†å²
        context += "å¯¹è¯å†å²:\n"
        for msg in self.messages:
            prefix = "ç”¨æˆ·: " if msg["role"] == "user" else "åŠ©æ‰‹: "
            context += f"{prefix}{msg['content']}\n"
        
        return context
```

**æ­¥éª¤3ï¼šæ•´åˆè®°å¿†ç³»ç»Ÿåˆ°Agent**

```python
# åˆ›å»ºå¸¦è®°å¿†çš„Agent
from langchain.chains.conversation.memory import ConversationBufferWindowMemory

# ä½¿ç”¨LangChainçš„çª—å£è®°å¿†
window_memory = ConversationBufferWindowMemory(
    k=5,  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
    return_messages=True,
    memory_key="chat_history"
)

# åˆ›å»ºå·¥å…·
tools_with_memory = tools.copy()  # ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„å·¥å…·

# åˆ›å»ºè®°å¿†Agentçš„æç¤ºè¯
memory_prompt = """ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿè®°ä½å¯¹è¯å†å²çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

å¯ç”¨å·¥å…·:
{tools}

å¯¹è¯å†å²:
{chat_history}

è¯·æ ¹æ®å¯¹è¯å†å²å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·è·å–æ›´å¤šä¿¡æ¯ã€‚

ç”¨æˆ·é—®é¢˜: {input}

{agent_scratchpad}
"""

memory_prompt_template = CustomPromptTemplate(
    template=memory_prompt,
    tools=tools_with_memory,
    input_variables=["input", "chat_history", "intermediate_steps"]
)

memory_llm_chain = LLMChain(llm=llm, prompt=memory_prompt_template)
memory_agent = LLMSingleActionAgent(
    llm_chain=memory_llm_chain,
    output_parser=agent.agent.output_parser,
    stop=["\nObservation:"],
    allowed_tools=[tool.name for tool in tools_with_memory]
)

memory_agent_executor = AgentExecutor.from_agent_and_tools(
    agent=memory_agent,
    tools=tools_with_memory,
    memory=window_memory,
    verbose=True
)
```

**æ­¥éª¤4ï¼šæµ‹è¯•è®°å¿†èƒ½åŠ›**

```python
# å¼€å§‹å¯¹è¯
print("å¼€å§‹è®°å¿†æµ‹è¯•å¯¹è¯ï¼š")

# ç¬¬ä¸€è½®å¯¹è¯
first_input = "ä½ å¥½ï¼Œæˆ‘å«ææ˜"
print(f"ç”¨æˆ·: {first_input}")
response = memory_agent_executor.run(first_input)
print(f"åŠ©æ‰‹: {response}\n")

# ç¬¬äºŒè½®å¯¹è¯
second_input = "æˆ‘æƒ³äº†è§£å›½å®¶å‘å±•é“¶è¡Œçš„æƒ…å†µ"
print(f"ç”¨æˆ·: {second_input}")
response = memory_agent_executor.run(second_input)
print(f"åŠ©æ‰‹: {response}\n")

# ç¬¬ä¸‰è½®å¯¹è¯ - æµ‹è¯•è®°å¿†èƒ½åŠ›
third_input = "ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ"
print(f"ç”¨æˆ·: {third_input}")
response = memory_agent_executor.run(third_input)
print(f"åŠ©æ‰‹: {response}\n")
```

### å®è·µ4ï¼šå·¥å…·ä½¿ç”¨ä¼˜åŒ–

åœ¨æœ¬å®è·µä¸­ï¼Œæˆ‘ä»¬å°†ä¼˜åŒ–Agentä½¿ç”¨å·¥å…·çš„æ•ˆç‡ã€‚

**æ­¥éª¤1ï¼šä¸ºAgentæ·»åŠ å¤šç§å·¥å…·**

```python
# å®šä¹‰æ›´å¤šå·¥å…·
search_tool = Tool(
    name="ç½‘ç»œæœç´¢",
    func=lambda q: f"æœç´¢ç»“æœ: å…³äº'{q}'çš„ä¿¡æ¯...",
    description="ç”¨äºåœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯ï¼Œé€‚ç”¨äºæŸ¥æ‰¾äº‹å®ã€æ–°é—»å’Œä¸€èˆ¬çŸ¥è¯†"
)

calculator_tool = Tool(
    name="è®¡ç®—å™¨",
    func=lambda exp: f"è®¡ç®—ç»“æœ: {eval(exp)}",
    description="ç”¨äºæ‰§è¡Œæ•°å­¦è®¡ç®—ï¼Œæ”¯æŒåŸºæœ¬è¿ç®—å¦‚åŠ å‡ä¹˜é™¤ã€å¹‚è¿ç®—ç­‰"
)

weather_tool = Tool(
    name="å¤©æ°”æŸ¥è¯¢",
    func=lambda loc: f"{loc}å¤©æ°”: æ™´å¤©ï¼Œ25Â°Cï¼Œå¾®é£",
    description="æŸ¥è¯¢æŒ‡å®šä½ç½®çš„å¤©æ°”æƒ…å†µï¼ŒåŒ…æ‹¬æ¸©åº¦ã€å¤©æ°”çŠ¶å†µå’Œé£åŠ›ç­‰"
)

translator_tool = Tool(
    name="ç¿»è¯‘åŠ©æ‰‹",
    func=lambda text: f"ç¿»è¯‘: {text} -> [ç¿»è¯‘ç»“æœ]",
    description="å°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ï¼Œæ”¯æŒå¤šç§è¯­è¨€å¯¹"
)

# åˆ›å»ºå·¥å…·é›†
advanced_tools = [search_tool, calculator_tool, weather_tool, translator_tool]
```

**æ­¥éª¤2ï¼šå®ç°å·¥å…·é€‰æ‹©ä¼˜åŒ–**

```python
class ToolSelectionOptimizer:
    def __init__(self, tools):
        self.tools = tools
        self.usage_stats = {tool.name: {"count": 0, "success_rate": 1.0} for tool in tools}
        self.tool_map = {tool.name: tool for tool in tools}
    
    def select_tools_for_task(self, task_description):
        """ä¸ºç‰¹å®šä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·"""
        relevant_tools = []
        
        # å…³é”®è¯åŒ¹é…ï¼ˆç®€åŒ–å®ç°ï¼‰
        keywords = {
            "æœç´¢": ["æœç´¢", "æŸ¥æ‰¾", "äº†è§£", "ä¿¡æ¯", "æ˜¯ä»€ä¹ˆ"],
            "è®¡ç®—å™¨": ["è®¡ç®—", "ç­‰äº", "åŠ ", "å‡", "ä¹˜", "é™¤", "æ•°å­¦"],
            "å¤©æ°”æŸ¥è¯¢": ["å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨", "æ°”å€™", "çƒ­", "å†·"],
            "ç¿»è¯‘åŠ©æ‰‹": ["ç¿»è¯‘", "ä¸­æ–‡", "è‹±æ–‡", "è¯­è¨€"]
        }
        
        for tool_name, words in keywords.items():
            if any(word in task_description for word in words) and tool_name in self.tool_map:
                relevant_tools.append(self.tool_map[tool_name])
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…ä»»ä½•å·¥å…·ï¼Œè¿”å›æœç´¢å·¥å…·ä½œä¸ºé»˜è®¤
        if not relevant_tools and "ç½‘ç»œæœç´¢" in self.tool_map:
            relevant_tools.append(self.tool_map["ç½‘ç»œæœç´¢"])
        
        return relevant_tools
    
    def update_stats(self, tool_name, success):
        """æ›´æ–°å·¥å…·ä½¿ç”¨ç»Ÿè®¡"""
        if tool_name in self.usage_stats:
            stats = self.usage_stats[tool_name]
            stats["count"] += 1
            
            # æ›´æ–°æˆåŠŸç‡ï¼ˆåŠ æƒå¹³å‡ï¼‰
            weight = min(0.1, 1.0 / stats["count"])  # éšä½¿ç”¨æ¬¡æ•°å¢åŠ æƒé‡å‡å°
            new_success = 1.0 if success else 0.0
            stats["success_rate"] = stats["success_rate"] * (1 - weight) + new_success * weight
    
    def get_tool_recommendations(self):
        """è·å–å·¥å…·æ¨èï¼ŒåŸºäºä½¿ç”¨é¢‘ç‡å’ŒæˆåŠŸç‡"""
        recommendations = sorted(
            self.usage_stats.items(),
            key=lambda x: (x[1]["success_rate"], x[1]["count"]),
            reverse=True
        )
        return recommendations
```

**æ­¥éª¤3ï¼šåˆ›å»ºå…·æœ‰å·¥å…·ä¼˜åŒ–çš„Agent**

```python
# å·¥å…·é€‰æ‹©ä¼˜åŒ–å™¨
tool_optimizer = ToolSelectionOptimizer(advanced_tools)

# è‡ªå®šä¹‰Agentç±»ï¼Œæ•´åˆå·¥å…·é€‰æ‹©ä¼˜åŒ–
class ToolOptimizedAgent:
    def __init__(self, agent_executor, tool_optimizer):
        self.agent = agent_executor
        self.tool_optimizer = tool_optimizer
    
    def run(self, input_text):
        # ä¸ºä»»åŠ¡é€‰æ‹©æœ€ä½³å·¥å…·
        selected_tools = self.tool_optimizer.select_tools_for_task(input_text)
        
        # åŠ¨æ€æ›´æ–°Agentçš„å·¥å…·é›†
        self.agent.tools = selected_tools
        
        # è®°å½•å·¥å…·é€‰æ‹©
        selected_tool_names = [tool.name for tool in selected_tools]
        print(f"ä¸ºä»»åŠ¡é€‰æ‹©çš„å·¥å…·: {selected_tool_names}")
        
        # æ‰§è¡ŒAgent
        try:
            result = self.agent.run(input_text)
            
            # å‡è®¾ä½¿ç”¨äº†ç¬¬ä¸€ä¸ªå·¥å…·ï¼Œå¹¶ä¸”æˆåŠŸ
            if selected_tools:
                self.tool_optimizer.update_stats(selected_tools[0].name, True)
                
            return result
        except Exception as e:
            # æ›´æ–°å¤±è´¥ç»Ÿè®¡
            if selected_tools:
                self.tool_optimizer.update_stats(selected_tools[0].name, False)
            
            return f"æ‰§è¡Œé”™è¯¯: {str(e)}"

# åˆ›å»ºä¼˜åŒ–çš„Agentæ‰§è¡Œå™¨
tool_optimized_agent_executor = AgentExecutor.from_agent_and_tools(
    agent=memory_agent,  # ä½¿ç”¨ä¹‹å‰çš„è®°å¿†Agent
    tools=advanced_tools,
    verbose=True
)

# åˆ›å»ºæœ€ç»ˆçš„ä¼˜åŒ–Agent
optimized_agent = ToolOptimizedAgent(tool_optimized_agent_executor, tool_optimizer)
```

**æ­¥éª¤4ï¼šæµ‹è¯•å·¥å…·ä¼˜åŒ–æ•ˆæœ**

```python
# æµ‹è¯•æ¡ˆä¾‹
tool_test_cases = [
    "å·´é»çš„åŸƒè²å°”é“å¡”æœ‰å¤šé«˜ï¼Ÿ",
    "è®¡ç®—123ä¹˜ä»¥456çš„ç»“æœ",
    "åŒ—äº¬æ˜å¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
    "æŠŠ'ä½ å¥½ï¼Œä¸–ç•Œ'ç¿»è¯‘æˆè‹±è¯­"
]

# æ‰§è¡Œæµ‹è¯•
for test in tool_test_cases:
    print(f"\nç”¨æˆ·: {test}")
    response = optimized_agent.run(test)
    print(f"åŠ©æ‰‹: {response}")

# æŸ¥çœ‹å·¥å…·ä½¿ç”¨ç»Ÿè®¡
print("\nå·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
recommendations = tool_optimizer.get_tool_recommendations()
for tool_name, stats in recommendations:
    print(f"{tool_name}: ä½¿ç”¨æ¬¡æ•° {stats['count']}, æˆåŠŸç‡ {stats['success_rate']:.2f}")
```

## ğŸ“ è‡ªæµ‹é—®é¢˜

å®Œæˆå­¦ä¹ åï¼Œå›ç­”ä»¥ä¸‹é—®é¢˜ä»¥æ£€éªŒä½ çš„ç†è§£ï¼š

1. Agentæ€§èƒ½è¯„ä¼°çš„ä¸»è¦æŒ‡æ ‡åŒ…æ‹¬å“ªäº›æ–¹é¢ï¼Ÿ
2. ä»€ä¹ˆæ˜¯A/Bæµ‹è¯•ï¼Œå®ƒå¦‚ä½•åº”ç”¨äºAgentä¼˜åŒ–ï¼Ÿ
3. ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯çš„ä¸‰ä¸ªå…³é”®æ–¹é¢æ˜¯ä»€ä¹ˆï¼Ÿ
4. Agentè®°å¿†ç³»ç»Ÿé€šå¸¸åŒ…æ‹¬å“ªå‡ ç§ç±»å‹çš„è®°å¿†ï¼Ÿå®ƒä»¬å„è‡ªçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ
5. å¦‚ä½•æœ‰æ•ˆç®¡ç†é•¿å¯¹è¯å†å²ä»¥é€‚åº”Tokené™åˆ¶ï¼Ÿ
6. ä¸“ä¸šé¢†åŸŸAgentå®šåˆ¶çš„ä¸»è¦æ­¥éª¤æœ‰å“ªäº›ï¼Ÿ
7. æé«˜Agentå·¥å…·ä½¿ç”¨æ•ˆç‡çš„ä¸‰ç§æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ
8. ä¸ºä»€ä¹ˆéœ€è¦ä¸ºAgentè®¾è®¡å®‰å…¨ä¸ä¼¦ç†æ§åˆ¶æœºåˆ¶ï¼Ÿå¸¸è§çš„æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ
9. å¦‚ä½•è¯„ä¼°Agentä¼˜åŒ–çš„æ•ˆæœï¼Ÿéœ€è¦å…³æ³¨å“ªäº›å˜åŒ–ï¼Ÿ
10. Agentåœ¨å¤„ç†ä¸ç¡®å®šæ€§æ—¶åº”é‡‡å–ä»€ä¹ˆç­–ç•¥ï¼Ÿ

### å‚è€ƒç­”æ¡ˆ

1. **Agentæ€§èƒ½è¯„ä¼°çš„ä¸»è¦æŒ‡æ ‡**ï¼š
   - ä»»åŠ¡å®Œæˆåº¦æŒ‡æ ‡ï¼šæˆåŠŸç‡ã€å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€è´¨é‡è¯„åˆ†
   - æ•ˆç‡æŒ‡æ ‡ï¼šå“åº”æ—¶é—´ã€ä»»åŠ¡å®Œæˆæ—¶é—´ã€äº¤äº’æ¬¡æ•°ã€èµ„æºæ¶ˆè€—ï¼ˆTokenä½¿ç”¨é‡ã€APIè°ƒç”¨æ¬¡æ•°ï¼‰
   - ç”¨æˆ·ä½“éªŒæŒ‡æ ‡ï¼šæ»¡æ„åº¦è¯„åˆ†ã€æ˜“ç”¨æ€§ã€æœ‰ç”¨æ€§ã€ä¿¡ä»»åº¦
   - ä¸“ä¸šèƒ½åŠ›æŒ‡æ ‡ï¼šä¸“ä¸šå‡†ç¡®æ€§ã€æ¨ç†èƒ½åŠ›ã€åˆ›æ–°èƒ½åŠ›ã€é€‚åº”æ€§

2. **A/Bæµ‹è¯•åŠå…¶åº”ç”¨**ï¼š
   A/Bæµ‹è¯•æ˜¯é€šè¿‡æ¯”è¾ƒä¸¤ä¸ªæˆ–å¤šä¸ªç‰ˆæœ¬çš„Agentåœ¨ç›¸åŒæ¡ä»¶ä¸‹çš„è¡¨ç°ï¼Œç¡®å®šå“ªç§é…ç½®æ›´æœ‰æ•ˆçš„æ–¹æ³•ã€‚åœ¨Agentä¼˜åŒ–ä¸­ï¼Œå®ƒå¯ç”¨äºæµ‹è¯•ä¸åŒçš„æç¤ºè¯ç­–ç•¥ã€æ¯”è¾ƒä¸åŒçš„è®°å¿†æœºåˆ¶ã€è¯„ä¼°ä¸åŒçš„å·¥å…·ç»„åˆã€éªŒè¯æ–°åŠŸèƒ½çš„æ•ˆæœç­‰ã€‚å…³é”®æ˜¯ç¡®ä¿æµ‹è¯•æ¡ä»¶ç›¸åŒï¼Œåªå˜æ›´ä¸€ä¸ªè¦ç´ ï¼Œå¹¶è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æã€‚

3. **ä¼˜åŒ–ç³»ç»Ÿæç¤ºè¯çš„ä¸‰ä¸ªå…³é”®æ–¹é¢**ï¼š
   - è§’è‰²å®šä¹‰ç²¾ç¡®åŒ–ï¼šæ˜ç¡®Agentçš„ä¸“ä¸šèº«ä»½ã€ç»éªŒæ°´å¹³å’Œä¸“é•¿é¢†åŸŸ
   - æŒ‡ä»¤ç»“æ„ä¼˜åŒ–ï¼šä½¿ç”¨åˆ†æ­¥éª¤ã€ç»“æ„åŒ–çš„æŒ‡ä»¤æé«˜è¡Œä¸ºä¸€è‡´æ€§
   - çº¦æŸæ¡ä»¶æ˜ç¡®åŒ–ï¼šè®¾ç½®æ¸…æ™°çš„è¡Œä¸ºè¾¹ç•Œã€è¾“å‡ºè§„èŒƒå’ŒçŸ¥è¯†é™åˆ¶

4. **Agentè®°å¿†ç³»ç»Ÿç±»å‹åŠä½œç”¨**ï¼š
   - å·¥ä½œè®°å¿†ï¼ˆçŸ­æœŸ/å³æ—¶ï¼‰ï¼šå­˜å‚¨å½“å‰ä»»åŠ¡çŠ¶æ€ã€ä¸´æ—¶æ¨ç†ç»“æœã€æ³¨æ„åŠ›ç„¦ç‚¹ç­‰
   - æƒ…æ™¯è®°å¿†ï¼ˆä¼šè¯çº§åˆ«ï¼‰ï¼šä¿å­˜å¯¹è¯å†å²ã€ç”¨æˆ·åå¥½ã€äº¤äº’æ¨¡å¼ç­‰
   - é•¿æœŸè®°å¿†ï¼ˆæŒä¹…çŸ¥è¯†ï¼‰ï¼šå­˜å‚¨é¢†åŸŸçŸ¥è¯†ã€è¿‡å¾€ç»éªŒã€è§„åˆ™æµç¨‹ç­‰
   è¿™ä¸‰ç§è®°å¿†ååŒå·¥ä½œï¼Œåˆ†åˆ«ç®¡ç†ä¸åŒæ—¶é—´è·¨åº¦å’Œé‡è¦æ€§çš„ä¿¡æ¯ã€‚

5. **ç®¡ç†é•¿å¯¹è¯å†å²çš„æ–¹æ³•**ï¼š
   - å¯¹è¯å†å²å‹ç¼©ï¼šå°†æ—©æœŸå¯¹è¯ç”Ÿæˆæ‘˜è¦æ›¿æ¢åŸå§‹å†…å®¹
   - é‡è¦ä¿¡æ¯æå–ï¼šè¯†åˆ«å¹¶ä¿ç•™å…³é”®ä¿¡æ¯ï¼Œä¸¢å¼ƒæ¬¡è¦å†…å®¹
   - ä¸Šä¸‹æ–‡çª—å£æ§åˆ¶ï¼šåŠ¨æ€è°ƒæ•´ä¿ç•™çš„ä¸Šä¸‹æ–‡é•¿åº¦
   - åˆ†å±‚è®°å¿†ç®¡ç†ï¼šå°†é¢‘ç¹ä½¿ç”¨çš„ä¿¡æ¯ä¿ç•™åœ¨å³æ—¶è®°å¿†ï¼Œå…¶ä»–å†…å®¹å­˜å‚¨åœ¨å¤–éƒ¨

6. **ä¸“ä¸šé¢†åŸŸAgentå®šåˆ¶çš„ä¸»è¦æ­¥éª¤**ï¼š
   - é¢†åŸŸçŸ¥è¯†æ³¨å…¥ï¼šæ·»åŠ ä¸“ä¸šæœ¯è¯­ã€é¢†åŸŸè§„åˆ™ã€å‚è€ƒèµ„æº
   - è¡Œä¸ºæ¨¡å¼å®šåˆ¶ï¼šè°ƒæ•´è¯­è¨€é£æ ¼ã€æ¨ç†è·¯å¾„ã€ä¸“ä¸šåˆ¤æ–­æ ‡å‡†
   - ä¸“ç”¨å·¥å…·é›†æˆï¼šé…ç½®é¢†åŸŸAPIã€ä¸“ä¸šåˆ†æå·¥å…·ã€æ•°æ®æº
   - æµ‹è¯•ä¸åé¦ˆï¼šä½¿ç”¨é¢†åŸŸä¸“å®¶éªŒè¯ã€åœ¨çœŸå®åœºæ™¯æµ‹è¯•ã€è¿­ä»£æ”¹è¿›

7. **æé«˜Agentå·¥å…·ä½¿ç”¨æ•ˆç‡çš„ä¸‰ç§æ–¹æ³•**ï¼š
   - å·¥å…·é€‰æ‹©ä¸ç»„åˆä¼˜åŒ–ï¼šåˆ†æå·¥å…·åŠŸèƒ½ã€è®¾è®¡æœ€ä½³ç»„åˆç­–ç•¥ã€å¤„ç†å·¥å…·ä¾èµ–
   - å‚æ•°ä¼ é€’ä¼˜åŒ–ï¼šä»ä¸Šä¸‹æ–‡æå–å‚æ•°ã€å»é™¤å†—ä½™å‚æ•°ã€æ ¼å¼åŒ–å‚æ•°å€¼
   - ç»“æœç¼“å­˜ç­–ç•¥ï¼šç¼“å­˜é‡å¤è°ƒç”¨ç»“æœã€å®ç°å¹¶è¡Œè°ƒç”¨ã€ä¼˜åŒ–å·¥å…·æè¿°

8. **Agentå®‰å…¨ä¸ä¼¦ç†æ§åˆ¶æœºåˆ¶**ï¼š
   éœ€è¦è®¾è®¡è¿™äº›æœºåˆ¶æ˜¯å› ä¸ºAgentå¯èƒ½é¢ä¸´å„ç§å®‰å…¨å’Œä¼¦ç†é£é™©ï¼Œå¦‚éšç§æ³„éœ²ã€æœ‰å®³å†…å®¹ã€åè§æ”¾å¤§ç­‰ã€‚å¸¸è§æ–¹æ³•åŒ…æ‹¬ï¼š
   - è¾“å…¥è¿‡æ»¤æœºåˆ¶ï¼šè¯†åˆ«å¹¶è¿‡æ»¤æ•æ„Ÿå†…å®¹ã€æœ‰å®³æŒ‡ä»¤ç­‰
   - è¾“å‡ºå®¡æŸ¥æœºåˆ¶ï¼šæ£€æŸ¥è¾“å‡ºå†…å®¹çš„å®‰å…¨æ€§ï¼Œç¼“è§£æ½œåœ¨é—®é¢˜
   - è¡Œä¸ºè¾¹ç•Œè®¾å®šï¼šæ˜ç¡®å®šä¹‰å…è®¸å’Œç¦æ­¢çš„è¡Œä¸º
   - éšç§ä¿æŠ¤æªæ–½ï¼šå¯¹æ•æ„Ÿä¿¡æ¯è¿›è¡Œè„±æ•å¤„ç†

9. **è¯„ä¼°Agentä¼˜åŒ–æ•ˆæœ**ï¼š
   åº”å…³æ³¨ä»¥ä¸‹å˜åŒ–ï¼š
   - æ€§èƒ½æŒ‡æ ‡æ”¹è¿›ï¼šå“åº”æ—¶é—´ã€ä»»åŠ¡å®Œæˆç‡ã€å‡†ç¡®æ€§çš„æå‡
   - èµ„æºåˆ©ç”¨å˜åŒ–ï¼šTokenæ¶ˆè€—ã€APIè°ƒç”¨æ¬¡æ•°çš„å‡å°‘
   - ç”¨æˆ·ä½“éªŒæå‡ï¼šæ»¡æ„åº¦ã€æ˜“ç”¨æ€§ã€äº¤äº’è½®æ¬¡çš„æ”¹è¿›
   - é”™è¯¯ç‡é™ä½ï¼šå¤±è´¥æ¡ˆä¾‹å‡å°‘ã€è¾¹ç¼˜æƒ…å†µå¤„ç†æ”¹å–„
   - ä¸“ä¸šèƒ½åŠ›æå‡ï¼šé¢†åŸŸå‡†ç¡®æ€§ã€æ¨ç†è´¨é‡çš„å¢å¼º

10. **Agentå¤„ç†ä¸ç¡®å®šæ€§çš„ç­–ç•¥**ï¼š
    - é€æ˜æ²Ÿé€šï¼šæ˜ç¡®è¡¨è¾¾ä¸ç¡®å®šç¨‹åº¦ï¼Œé¿å…è™šå‡è‡ªä¿¡
    - ä¸»åŠ¨æ¾„æ¸…ï¼šè¯†åˆ«ä¸æ˜ç¡®çš„é—®é¢˜éƒ¨åˆ†ï¼Œè¯·æ±‚ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯
    - å¤‡é€‰æ–¹æ¡ˆæä¾›ï¼šæä¾›å¤šä¸ªå¯èƒ½ç­”æ¡ˆå¹¶è§£é‡Šä¾æ®
    - æ¦‚ç‡è¡¨è¿°ï¼šä½¿ç”¨æ¦‚ç‡è¯­è¨€è¡¨è¾¾ä¸åŒå¯èƒ½æ€§
    - ä¿¡æ¯æ¥æºå¼•ç”¨ï¼šå¼•ç”¨ä¿¡æ¯æºï¼Œè®©ç”¨æˆ·è‡ªè¡Œåˆ¤æ–­å¯é æ€§

## ğŸ“š æ‹“å±•èµ„æº

### å­¦æœ¯è®ºæ–‡

1. **[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)**
   - å‘è¡¨äº2022å¹´ï¼Œä»‹ç»äº†å°†æ¨ç†ä¸è¡ŒåŠ¨ç»“åˆçš„Agentæ¡†æ¶
   - æä¾›äº†Agentæ€ç»´é“¾ä¸å·¥å…·ä½¿ç”¨çš„ç†è®ºåŸºç¡€

2. **[Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761)**
   - å‘è¡¨äº2023å¹´ï¼Œæ¢è®¨è¯­è¨€æ¨¡å‹è‡ªä¸»å­¦ä¹ ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›
   - æä¾›äº†è‡ªåŠ¨å·¥å…·é€‰æ‹©å’Œè°ƒç”¨çš„æŠ€æœ¯å®ç°

3. **[Evaluating and Improving Tool-Augmented Computation-Intensive Reasoning](https://arxiv.org/abs/2310.00749)**
   - ä¸“æ³¨äºå¦‚ä½•è¯„ä¼°å’Œæå‡Agentçš„æ¨ç†èƒ½åŠ›
   - æä¾›äº†ä¸€å¥—ç³»ç»ŸåŒ–çš„Agentè¯„ä¼°æ–¹æ³•è®º

### è§†é¢‘æ•™ç¨‹

1. **[å¦‚ä½•ä¼˜åŒ–GPTæç¤ºè¯æ¡†æ¶](https://www.youtube.com/watch?v=H4YK_7MAckk)**
   - Andrew Ngå’ŒOpenAIåˆä½œçš„æç¤ºè¯ä¼˜åŒ–æ•™ç¨‹ (æ­¤ä¸ºDeepLearning.AIç³»åˆ—è¯¾ç¨‹ä»‹ç»ï¼Œå»ºè®®æŸ¥çœ‹å®Œæ•´æ’­æ”¾åˆ—è¡¨æˆ–ç›¸å…³è§†é¢‘)
   - è¯¦ç»†è®²è§£äº†æç¤ºè¯å·¥ç¨‹çš„æœ€ä½³å®è·µ

2. **[Harrison Chase - Agents Masterclass from LangChain](https://www.youtube.com/watch?v=DWUdGhRrv2c)**
   - ç”±LangChainåˆ›å§‹äººHarrison Chaseä¸»è®²
   - ä»‹ç»å¦‚ä½•æ„å»ºç”Ÿäº§çº§åˆ«çš„AI Agent

3. **[Anthropic's Blueprint for Building Lean, Powerful AI Agents](https://www.youtube.com/watch?v=JEERoZQbG9k)**
   - ç”±AnthropicAIå·¥ç¨‹å¸ˆä¸»è®²
   - è¯¦ç»†ä»‹ç»Agentç³»ç»Ÿä»åŸå‹åˆ°ç”Ÿäº§çš„å…¨æµç¨‹

4. **[AutoGen Agents with Unlimited Memory Using MemGPT (Tutorial)](https://www.youtube.com/watch?v=VJ6bK81meu8)**
   - ä¸“æ³¨äºAgentè®°å¿†ç®¡ç†çš„æŠ€æœ¯è®²è§£ (æ­¤è§†é¢‘ä»¥AutoGenå’ŒMemGPTä¸ºä¾‹)
   - åŒ…å«å®é™…ä»£ç å®ç°å’Œæ¡ˆä¾‹åˆ†æ

### å·¥å…·ä¸æ¡†æ¶

1. **[LangChain](https://github.com/langchain-ai/langchain)**
   - åŠŸèƒ½å…¨é¢çš„AIåº”ç”¨å¼€å‘æ¡†æ¶
   - æä¾›äº†ä¸°å¯Œçš„Agentç»„ä»¶å’Œè¯„ä¼°å·¥å…·

2. **[LlamaIndex](https://github.com/jerryjliu/llama_index)**
   - ä¸“æ³¨äºçŸ¥è¯†æ£€ç´¢å’Œç®¡ç†çš„æ¡†æ¶
   - é€‚åˆæ„å»ºæœ‰è®°å¿†å’ŒçŸ¥è¯†åº“çš„Agent

3. **[Ragas](https://github.com/explodinggradients/ragas)**
   - ä¸“é—¨ç”¨äºè¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•RAGç³»ç»Ÿçš„å·¥å…·
   - å¯ç”¨äºAgentç›¸å…³ç»„ä»¶çš„æ€§èƒ½æµ‹è¯•

4. **[LangSmith](https://smith.langchain.com/)**
   - LangChainæ¨å‡ºçš„è¯„ä¼°å’Œç›‘æ§å¹³å°
   - æä¾›Agentè¡Œä¸ºè¿½è¸ªå’Œæ€§èƒ½åˆ†æ

5. **[MemGPT](https://github.com/cpacker/MemGPT)**
   - ä¸“æ³¨äºé•¿æœŸè®°å¿†ç®¡ç†çš„Agentæ¡†æ¶
   - å®ç°äº†é«˜æ•ˆçš„ä¸Šä¸‹æ–‡å‹ç¼©å’Œæ£€ç´¢

### åœ¨çº¿è¯¾ç¨‹ä¸æ•™ç¨‹

1. **[Prompt Engineering for ChatGPT](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)**
   - DeepLearning.AIè¯¾ç¨‹ï¼Œå®Œå…¨å…è´¹
   - æä¾›æç¤ºè¯ä¼˜åŒ–çš„ç³»ç»ŸçŸ¥è¯†

2. **[LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)**
   - å¿«é€Ÿå…¥é—¨LangChainçš„å…è´¹è¯¾ç¨‹
   - åŒ…å«Agentæ„å»ºå®è·µ

3. **[Building Systems with the ChatGPT API](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)**
   - ä»‹ç»å¦‚ä½•æ„å»ºåŸºäºChatGPTçš„ç³»ç»Ÿ
   - åŒ…å«è¯„ä¼°å’Œä¼˜åŒ–éƒ¨åˆ†

4. **[Function Calling and Agents with LangChain](https://learn.deeplearning.ai/functions-tools-agents-langchain/lesson/1/introduction)**
   - ä¸“æ³¨äºå‡½æ•°è°ƒç”¨å’ŒAgentå¼€å‘
   - æä¾›è¯¦ç»†çš„ä»£ç ç¤ºä¾‹

### åšå®¢ä¸æ–‡ç« 

1. **[Agent-Based LLM Architectures](https://eugeneyan.com/writing/llm-patterns/#agents-to-orchestrate-action)**
   - Eugene Yançš„æƒå¨åšå®¢
   - å…¨é¢ç»¼è¿°Agentæ¶æ„æ¨¡å¼å’Œä¼˜åŒ–ç­–ç•¥

2. **[Building, Testing, and Improving LLM Agents](https://www.promptingguide.ai/research/agents)**
   - PromptingGuideç½‘ç«™çš„AgentæŒ‡å—
   - æä¾›ç³»ç»ŸåŒ–çš„Agentæ„å»ºæ–¹æ³•

3. **[How to evaluate LLMs for production](https://www.surgehq.ai/blog/evaluating-llms-for-production)**
   - å…³äºLLMè¯„ä¼°çš„è¯¦ç»†æŒ‡å—
   - é€‚ç”¨äºAgentæ€§èƒ½è¯„ä¼°

4. **[Emerging Architectures for LLM Applications](https://a16z.com/emerging-architectures-for-llm-applications/)**
   - a16zå‘å¸ƒçš„LLMåº”ç”¨æ¶æ„ç»¼è¿°
   - åŒ…å«å¯¹Agentæ¶æ„çš„åˆ†æ

## ğŸ“ ä½œä¸šä¸æ€è€ƒé¢˜

### åŸºç¡€ä½œä¸š

1. **Agentæ€§èƒ½åˆ†ææŠ¥å‘Š**
   é€‰æ‹©ä¸€ä¸ªç°æœ‰çš„AI Agentï¼ˆå¯ä»¥æ˜¯è¯¾ç¨‹ä¸­çš„ç¤ºä¾‹æˆ–å…¬å¼€çš„é¡¹ç›®ï¼‰ï¼Œå¯¹å…¶æ€§èƒ½è¿›è¡Œåˆ†æï¼Œå¹¶æ’°å†™ä¸€ä»½è¯„ä¼°æŠ¥å‘Šã€‚æŠ¥å‘Šåº”åŒ…å«ï¼š
   - è‡³å°‘3ç§è¯„ä¼°æŒ‡æ ‡çš„å…·ä½“æ•°æ®
   - è¯†åˆ«å‡ºçš„2-3ä¸ªä¸»è¦æ€§èƒ½ç“¶é¢ˆ
   - æ˜ç¡®çš„ä¼˜åŒ–å»ºè®®å’Œé¢„æœŸæ•ˆæœ

2. **æç¤ºè¯ä¼˜åŒ–å®éªŒ**
   è®¾è®¡ä¸€ä¸ªæç¤ºè¯ä¼˜åŒ–å®éªŒï¼Œå¯¹åŒä¸€ä»»åŠ¡ä½¿ç”¨3ç§ä¸åŒçš„ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶æ¯”è¾ƒæ•ˆæœå·®å¼‚ï¼š
   - åˆ›å»ºåŸºå‡†ç‰ˆã€ä¼˜åŒ–ç‰ˆAå’Œä¼˜åŒ–ç‰ˆBçš„ç³»ç»Ÿæç¤ºè¯
   - ä½¿ç”¨ç›¸åŒçš„5ä¸ªæµ‹è¯•ç”¨ä¾‹è¯„ä¼°ä¸‰ä¸ªç‰ˆæœ¬
   - è®°å½•å¹¶åˆ†ææ€§èƒ½å·®å¼‚ï¼Œæ€»ç»“æœ€æœ‰æ•ˆçš„æç¤ºç­–ç•¥

3. **è®°å¿†ç³»ç»Ÿè®¾è®¡**
   ä¸ºç‰¹å®šç±»å‹çš„Agentï¼ˆå¦‚é•¿æœŸä¸ªäººåŠ©æ‰‹ï¼‰è®¾è®¡ä¸€ä¸ªé€‚åˆçš„è®°å¿†ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
   - è®°å¿†æ¶æ„å›¾ï¼ˆåŒ…å«çŸ­æœŸã€ä¼šè¯å’Œé•¿æœŸè®°å¿†ç»„ä»¶ï¼‰
   - è¯¦ç»†è¯´æ˜å„ç»„ä»¶çš„æ•°æ®ç»“æ„å’Œå­˜å‚¨å†…å®¹
   - æè¿°è®°å¿†æ›´æ–°å’Œæ£€ç´¢çš„æœºåˆ¶å’Œç®—æ³•
   - æä¾›ç¤ºä¾‹ä»£ç å®ç°å…³é”®åŠŸèƒ½

### è¿›é˜¶ä½œä¸š

4. **ä¸“ä¸šé¢†åŸŸAgentå®šåˆ¶**
   é€‰æ‹©ä¸€ä¸ªä¸“ä¸šé¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ã€é‡‘èã€æ•™è‚²ç­‰ï¼‰ï¼Œå°†é€šç”¨Agentæ”¹é€ æˆè¯¥é¢†åŸŸçš„ä¸“å®¶Agentï¼š
   - æ”¶é›†å¹¶ç»„ç»‡è‡³å°‘30æ¡é¢†åŸŸä¸“ä¸šçŸ¥è¯†
   - è®¾è®¡ä¸“ä¸šåŒ–çš„ç³»ç»Ÿæç¤ºè¯
   - å®ç°é¢†åŸŸç‰¹å®šçš„å·¥å…·æ¥å£ï¼ˆå¯ä»¥æ¨¡æ‹Ÿå®ç°ï¼‰
   - é€šè¿‡10ä¸ªä¸“ä¸šé—®é¢˜æµ‹è¯•å¹¶è¯„ä¼°æ•ˆæœ
   - æ’°å†™é¢†åŸŸAgentçš„ä¼˜åŒ–æŠ¥å‘Š

5. **Agentè‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶å®ç°**
   è®¾è®¡å¹¶å®ç°ä¸€ä¸ªè‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å’Œä¼˜åŒ–AI Agentï¼š
   - åˆ›å»ºå¤šä¸ªæµ‹è¯•ç”¨ä¾‹é›†ï¼Œè¦†ç›–ä¸åŒèƒ½åŠ›å’Œåœºæ™¯
   - å®ç°è‡ªåŠ¨æ‰§è¡Œæµ‹è¯•å¹¶æ”¶é›†æ€§èƒ½æŒ‡æ ‡çš„åŠŸèƒ½
   - æä¾›æµ‹è¯•ç»“æœå¯è§†åŒ–å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
   - æ”¯æŒA/Bæµ‹è¯•æ¯”è¾ƒä¸åŒAgenté…ç½®
   - åŒ…å«è‡ªåŠ¨è¯†åˆ«é—®é¢˜å¹¶æå‡ºä¼˜åŒ–å»ºè®®çš„åŠŸèƒ½

### æ€è€ƒé¢˜

1. Agentä¼˜åŒ–è¿‡ç¨‹ä¸­å¦‚ä½•å¹³è¡¡é€šç”¨æ€§å’Œä¸“ä¸šæ€§ï¼Ÿè¿‡åº¦ä¸“ä¸šåŒ–ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Œå¦‚ä½•é¿å…ï¼Ÿ

2. éšç€Agentå˜å¾—æ›´åŠ å¤æ‚å’Œè‡ªä¸»ï¼Œå¯èƒ½ä¼šå‡ºç°å“ªäº›å®‰å…¨å’Œä¼¦ç†é£é™©ï¼Ÿä½œä¸ºå¼€å‘è€…ï¼Œåº”è¯¥å¦‚ä½•è´Ÿè´£ä»»åœ°è®¾è®¡å’Œéƒ¨ç½²Agentç³»ç»Ÿï¼Ÿ

3. å½“Agentä½¿ç”¨å¤šä¸ªLLMæ¨¡å‹åä½œæ—¶ï¼ˆå¦‚ä¸åŒå±‚æ¬¡æˆ–ä¸åŒåŠŸèƒ½çš„æ¨¡å‹ç»„åˆï¼‰ï¼Œä¼šå‡ºç°å“ªäº›ç‰¹æ®Šçš„ä¼˜åŒ–æŒ‘æˆ˜ï¼Ÿå¦‚ä½•è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Ÿ

4. Agentç³»ç»Ÿçš„å¯è§£é‡Šæ€§å¯¹ç”¨æˆ·ä¿¡ä»»æœ‰ä½•å½±å“ï¼Ÿå¦‚ä½•åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æé«˜Agentå†³ç­–å’Œè¡Œä¸ºçš„å¯è§£é‡Šæ€§ï¼Ÿ

5. æœªæ¥äº”å¹´å†…ï¼ŒAgentæŠ€æœ¯å¯èƒ½ä¼šå¦‚ä½•å‘å±•ï¼Ÿè¿™äº›å‘å±•ä¼šå¦‚ä½•æ”¹å˜å½“å‰çš„Agentä¼˜åŒ–æ–¹æ³•å’Œæœ€ä½³å®è·µï¼Ÿ

## ğŸ”® æ˜æ—¥é¢„å‘Š

æ˜å¤©æˆ‘ä»¬å°†è¿›å…¥è¯¾ç¨‹çš„ç¬¬ä¸‰é˜¶æ®µï¼Œå¼€å§‹æ¢ç´¢MCPï¼ˆMulti-agent Collaborative Programmingï¼Œå¤šæ™ºèƒ½ä½“åä½œç¼–ç¨‹ï¼‰æŠ€æœ¯ã€‚æˆ‘ä»¬å°†ä»MCPçš„åŸºæœ¬æ¦‚å¿µã€æ ¸å¿ƒåŸç†å’ŒæŠ€æœ¯åŸºç¡€å¼€å§‹ï¼Œäº†è§£è¿™ä¸€é©å‘½æ€§çš„å¼€å‘èŒƒå¼å¦‚ä½•æå‡AIè¾…åŠ©ç¼–ç¨‹çš„æ•ˆç‡å’Œè´¨é‡ã€‚

å‡†å¤‡å¥½ä½ çš„ç¼–ç¨‹ç¯å¢ƒï¼Œæˆ‘ä»¬å°†åœ¨å®è·µä¸­ä½“éªŒå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¦‚ä½•ååŒå·¥ä½œï¼Œå…±åŒå®Œæˆå¤æ‚çš„ç¼–ç¨‹ä»»åŠ¡ï¼


---

> [ç‚¹å‡»é“¾æ¥åŠ å…¥ç¾¤èŠã€Aries - AIGCè‡ªå­¦äº¤æµç¾¤ã€‘ï¼šhttps://qm.qq.com/q/q88ZpofKLY](https://qm.qq.com/q/q88ZpofKLY) 